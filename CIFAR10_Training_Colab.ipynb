{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a721f5ae",
      "metadata": {
        "id": "a721f5ae"
      },
      "source": [
        "# CIFAR-10 CNN Training with PyTorch - Self-Contained Notebook\n",
        "\n",
        "This notebook contains all the code for training a CIFAR-10 CNN model with advanced features:\n",
        "- C1C2C3C4 architecture with Depthwise Separable and Dilated Convolutions\n",
        "- Albumentations data augmentation\n",
        "- Global Average Pooling (GAP)\n",
        "- Receptive field > 44 pixels\n",
        "- < 200k parameters\n",
        "\n",
        "**All code is embedded in this single notebook - no external files needed!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5aca5fbf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aca5fbf",
        "outputId": "712d753b-4dba-496d-a981-7feb2db4cfb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.12/dist-packages (1.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.12/dist-packages (2.0.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from albumentations) (1.16.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from albumentations) (6.0.2)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.12/dist-packages (from albumentations) (2.11.9)\n",
            "Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.12/dist-packages (from albumentations) (0.0.24)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.12/dist-packages (from albumentations) (4.12.0.88)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations) (4.0.11)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations) (6.5.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install torch torchvision torchsummary numpy matplotlib albumentations tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "da699497",
      "metadata": {
        "id": "da699497"
      },
      "outputs": [],
      "source": [
        "# ================================\n",
        "# logger_setup.py - Logging Setup\n",
        "# ================================\n",
        "import logging\n",
        "import os\n",
        "\n",
        "_LOGGING_INITIALIZED = False\n",
        "\n",
        "class TqdmLoggingHandler(logging.StreamHandler):\n",
        "    \"\"\"A logging handler that plays nicely with tqdm progress bars.\"\"\"\n",
        "    def emit(self, record):\n",
        "        try:\n",
        "            from tqdm import tqdm  # Lazy import so tqdm isn't a hard dependency\n",
        "            msg = self.format(record)\n",
        "            tqdm.write(msg)\n",
        "        except Exception:\n",
        "            # Fallback to normal stream behavior\n",
        "            super().emit(record)\n",
        "\n",
        "def setup_logging(log_to_file=False, log_dir='logs'):\n",
        "    \"\"\"Set up simple logging configuration.\n",
        "\n",
        "    Args:\n",
        "        log_to_file (bool): If True, also log to a file (default: False)\n",
        "        log_dir (str): Directory for log files if log_to_file is True\n",
        "    \"\"\"\n",
        "    global _LOGGING_INITIALIZED\n",
        "\n",
        "    # If already initialized, don't recreate handlers (prevents truncation mid-run)\n",
        "    if _LOGGING_INITIALIZED:\n",
        "        logger = logging.getLogger()\n",
        "        # If file logging is requested and not present yet, add it (append mode)\n",
        "        if log_to_file and not any(isinstance(h, logging.FileHandler) for h in logger.handlers):\n",
        "            try:\n",
        "                if not os.path.exists(log_dir):\n",
        "                    os.makedirs(log_dir, exist_ok=True)\n",
        "                log_file = os.path.join(log_dir, 'training.log')\n",
        "                file_handler = logging.FileHandler(log_file, mode='a', encoding='utf-8')\n",
        "                file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
        "                file_handler.setLevel(logging.INFO)\n",
        "                logger.addHandler(file_handler)\n",
        "            except Exception:\n",
        "                pass\n",
        "        return logger\n",
        "\n",
        "    # Configure basic logging format\n",
        "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "    # Set up console handler\n",
        "    console_handler = TqdmLoggingHandler()\n",
        "    console_handler.setFormatter(formatter)\n",
        "    console_handler.setLevel(logging.INFO)\n",
        "\n",
        "    # Configure root logger\n",
        "    root_logger = logging.getLogger()\n",
        "    root_logger.setLevel(logging.INFO)\n",
        "\n",
        "    # Remove any existing handlers to avoid duplicates\n",
        "    for handler in root_logger.handlers[:]:\n",
        "        root_logger.removeHandler(handler)\n",
        "\n",
        "    # Add console handler\n",
        "    root_logger.addHandler(console_handler)\n",
        "\n",
        "    # Add file handler if requested\n",
        "    if log_to_file:\n",
        "        try:\n",
        "            if not os.path.exists(log_dir):\n",
        "                os.makedirs(log_dir, exist_ok=True)\n",
        "            log_file = os.path.join(log_dir, 'training.log')\n",
        "            # Truncate once at initial setup to start fresh, then use append mode\n",
        "            try:\n",
        "                with open(log_file, 'w', encoding='utf-8'):\n",
        "                    pass\n",
        "            except Exception:\n",
        "                # If truncation fails, proceed; handler will create/append\n",
        "                pass\n",
        "            file_handler = logging.FileHandler(log_file, mode='a', encoding='utf-8')\n",
        "            file_handler.setFormatter(formatter)\n",
        "            file_handler.setLevel(logging.INFO)\n",
        "            root_logger.addHandler(file_handler)\n",
        "        except Exception:\n",
        "            # Silently continue with console-only logging if file logging fails\n",
        "            pass\n",
        "\n",
        "    _LOGGING_INITIALIZED = True\n",
        "    return root_logger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ef97e581",
      "metadata": {
        "id": "ef97e581"
      },
      "outputs": [],
      "source": [
        "# ================================\n",
        "# data_setup.py - Data Loading & Augmentation\n",
        "# ================================\n",
        "import torch.utils as utils\n",
        "from torchvision import datasets\n",
        "import numpy as np\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "class AlbumentationsTransform:\n",
        "    \"\"\"Wrapper to make Albumentations compatible with PyTorch datasets\"\"\"\n",
        "    def __init__(self, transform):\n",
        "        self.transform = transform\n",
        "\n",
        "    def __call__(self, img):\n",
        "        # Convert PIL to numpy\n",
        "        img = np.array(img)\n",
        "        # Apply albumentations transform\n",
        "        transformed = self.transform(image=img)\n",
        "        return transformed['image']\n",
        "\n",
        "class DataSetup:\n",
        "    def __init__(self, batch_size_train=64, batch_size_test=1000, shuffle_train=True, shuffle_test=False, num_workers=2, pin_memory=None, train_transforms=None, test_transforms=None):\n",
        "        self.batch_size_train = batch_size_train\n",
        "        self.batch_size_test = batch_size_test\n",
        "        self.shuffle_train = shuffle_train\n",
        "        self.shuffle_test = shuffle_test\n",
        "        self.num_workers = num_workers\n",
        "        self.pin_memory = pin_memory\n",
        "        self.train_transforms = train_transforms if train_transforms else self.get_train_transforms()\n",
        "        self.test_transforms = test_transforms if test_transforms else self.get_test_transforms()\n",
        "        self.train_loader = self.get_train_loader()\n",
        "        self.test_loader = self.get_test_loader()\n",
        "\n",
        "    def get_train_transforms(self):\n",
        "        \"\"\"Albumentations transforms for training with required augmentations\"\"\"\n",
        "        # CIFAR-10 mean: (0.4914, 0.4822, 0.4465) -> [125, 123, 114] for 0-255 range\n",
        "        fill_value = [125, 123, 114]\n",
        "\n",
        "        train_transform = A.Compose([\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.ShiftScaleRotate(\n",
        "                shift_limit=0.1,\n",
        "                scale_limit=0.1,\n",
        "                rotate_limit=15,\n",
        "                p=0.5\n",
        "            ),\n",
        "            A.CoarseDropout(\n",
        "                max_holes=1,\n",
        "                max_height=16,\n",
        "                max_width=16,\n",
        "                min_holes=1,\n",
        "                min_height=16,\n",
        "                min_width=16,\n",
        "                fill_value=fill_value,\n",
        "                mask_fill_value=None,\n",
        "                p=0.5\n",
        "            ),\n",
        "            A.Normalize(\n",
        "                mean=(0.4914, 0.4822, 0.4465),\n",
        "                std=(0.2470, 0.2435, 0.2616)\n",
        "            ),\n",
        "            ToTensorV2()\n",
        "        ])\n",
        "        return AlbumentationsTransform(train_transform)\n",
        "\n",
        "    def get_test_transforms(self):\n",
        "        \"\"\"Albumentations transforms for testing (only normalization)\"\"\"\n",
        "        test_transform = A.Compose([\n",
        "            A.Normalize(\n",
        "                mean=(0.4914, 0.4822, 0.4465),\n",
        "                std=(0.2470, 0.2435, 0.2616)\n",
        "            ),\n",
        "            ToTensorV2()\n",
        "        ])\n",
        "        return AlbumentationsTransform(test_transform)\n",
        "\n",
        "    def get_train_datasets(self):\n",
        "        return datasets.CIFAR10('../data', train=True, download=True, transform=self.train_transforms)\n",
        "\n",
        "    def get_test_datasets(self):\n",
        "        return datasets.CIFAR10('../data', train=False, download=True, transform=self.test_transforms)\n",
        "\n",
        "    def get_train_loader(self):\n",
        "        train_dataset = self.get_train_datasets()\n",
        "        return utils.data.DataLoader(train_dataset, batch_size=self.batch_size_train, shuffle=self.shuffle_train, num_workers=self.num_workers, pin_memory=self.pin_memory)\n",
        "\n",
        "    def get_test_loader(self):\n",
        "        test_dataset = self.get_test_datasets()\n",
        "        return utils.data.DataLoader(test_dataset, batch_size=self.batch_size_test, shuffle=self.shuffle_test, num_workers=self.num_workers, pin_memory=self.pin_memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "12524f6f",
      "metadata": {
        "id": "12524f6f"
      },
      "outputs": [],
      "source": [
        "# ================================\n",
        "# cifar10model_v0.py - Model Architecture\n",
        "# ================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class DepthwiseSeparableConv(nn.Module):\n",
        "    \"\"\"Depthwise Separable Convolution = Depthwise + Pointwise\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
        "        super(DepthwiseSeparableConv, self).__init__()\n",
        "\n",
        "        # Depthwise: each input channel convolved separately\n",
        "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size,\n",
        "                                 stride=stride, padding=padding, groups=in_channels, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
        "\n",
        "        # Pointwise: 1x1 conv to mix channels\n",
        "        self.pointwise = nn.Conv2d(in_channels, out_channels, 1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.depthwise(x)))\n",
        "        x = F.relu(self.bn2(self.pointwise(x)))\n",
        "        return x\n",
        "\n",
        "class Net(nn.Module):\n",
        "    \"\"\"CIFAR-10 CNN with C1C2C3C4 architecture, Depthwise Sep Conv, Dilated Conv, and GAP.\"\"\"\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        # C1: Initial feature extraction (32x32 -> 32x32)\n",
        "        self.c1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 8, 3, padding=1, bias=False),    # 32x32x8, RF=3\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.05),\n",
        "            nn.Conv2d(8, 16, 3, padding=1, bias=False),   # 32x32x16, RF=5\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.05),\n",
        "            nn.Conv2d(16, 32, 3, padding=1, bias=False),  # 32x32x32, RF=7\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.05),\n",
        "        )\n",
        "\n",
        "        # C2: Feature extraction with Dilated Convolutions (32x32 -> 32x32)\n",
        "        self.c2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 32, 3, padding=0, dilation=1, bias=False),  # 32x32x32, RF=9\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.05),\n",
        "            nn.Conv2d(32, 32, 3, padding=2, dilation=2, bias=False),  # 32x32x32, RF=13\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.05),\n",
        "            nn.Conv2d(32, 32, 3, padding=0, dilation=1, bias=False),  # 32x32x32, RF=21\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.05),\n",
        "        )\n",
        "\n",
        "        # C3: Pattern recognition with Depthwise Separable Conv (32x32 -> 16x16)\n",
        "        self.c3 = nn.Sequential(\n",
        "            nn.Conv2d(32, 32, 3, padding=1, stride=2),  # 32x32x32 -> 16x16x32, RF=23\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            DepthwiseSeparableConv(32, 64, kernel_size=3, stride=1, padding=1),  # 16x16x64, RF=25\n",
        "            nn.Conv2d(64, 64, 3, padding=1, bias=False),  # 16x16x64, RF=27\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.05),\n",
        "\n",
        "        )\n",
        "\n",
        "        # C4: Final convolution with stride=2 (16x16 -> 8x8), then GAP + FC\n",
        "        self.c4 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, 3, stride=1, padding=1, bias=False),  # 8x8x128, RF=55\n",
        "            #nn.BatchNorm2d(128),\n",
        "            #nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d(1),  # 1x1x128, RF=covers entire input\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128, 10)  # FC after GAP to target classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.c1(x)\n",
        "        x = self.c2(x)\n",
        "        x = self.c3(x)\n",
        "        x = self.c4(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "class set_config_v0:\n",
        "    \"\"\"Basic configuration for CIFAR-10 training.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.epochs = 35\n",
        "        self.nll_loss = torch.nn.NLLLoss()\n",
        "        self.criterion = self.nll_loss\n",
        "\n",
        "    def setup(self, model, use_onecycle: bool = True):\n",
        "        self.use_onecycle = use_onecycle\n",
        "        base_lr = 0.01\n",
        "        self.optimizer = torch.optim.SGD(model.parameters(), lr=base_lr, momentum=0.9)\n",
        "        self.device = next(model.parameters()).device\n",
        "        self.dataloader_args = self.get_dataloader_args()\n",
        "        self.data_setup_instance = DataSetup(**self.dataloader_args)\n",
        "        if self.use_onecycle:\n",
        "            steps_per_epoch = len(self.data_setup_instance.train_loader)\n",
        "            self.scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "                self.optimizer,\n",
        "                max_lr=base_lr,\n",
        "                epochs=self.epochs,\n",
        "                steps_per_epoch=steps_per_epoch,\n",
        "                pct_start=0.2,\n",
        "                div_factor=10,\n",
        "                final_div_factor=100,\n",
        "                anneal_strategy='cos'\n",
        "            )\n",
        "            self.scheduler.batch_step = True\n",
        "            logging.getLogger().info(\n",
        "                f\"Model v0: OneCycleLR max_lr={base_lr} pct_start=0.2 div_factor=10 final_div_factor=100 epochs={self.epochs}\"\n",
        "            )\n",
        "        else:\n",
        "            self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=6, gamma=0.1)\n",
        "            self.scheduler.batch_step = False\n",
        "            logging.getLogger().info(\n",
        "                f\"Model v0: StepLR lr={base_lr} step_size=6 gamma=0.1\"\n",
        "            )\n",
        "        logging.getLogger().info(f\"Dataloader arguments: {self.dataloader_args}\")\n",
        "        return self\n",
        "\n",
        "    def get_dataloader_args(self):\n",
        "        if hasattr(self, 'device') and self.device.type == \"cuda\":\n",
        "            args = dict(batch_size_train=32, batch_size_test=1000, shuffle_train=True, shuffle_test=False,\n",
        "                        num_workers=2, pin_memory=True)\n",
        "        else:\n",
        "            args = dict(batch_size_train=32, batch_size_test=1000, shuffle_train=True, shuffle_test=False)\n",
        "        logging.info(f\"Model v0 dataloader args: {args}\")\n",
        "        return args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "95bcf945",
      "metadata": {
        "id": "95bcf945"
      },
      "outputs": [],
      "source": [
        "# ================================\n",
        "# train_test.py - Training & Testing Logic\n",
        "# ================================\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import logging\n",
        "\n",
        "class train_test_model:\n",
        "\n",
        "    def __init__(self, model, device, train_loader, test_loader,criterion,optimizer,scheduler,epochs=1):\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.train_loader = train_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "        self.train_acc_list = []\n",
        "        self.test_acc_list = []\n",
        "        self.F = F  # Assign torch.nn.functional to self.F for easier access\n",
        "        self.epochs = epochs\n",
        "\n",
        "    def train(self, model, device, train_loader, optimizer, criterion,epoch):\n",
        "        self.model.train()\n",
        "        pbar = tqdm(self.train_loader, desc=\"Training\", leave=True)\n",
        "        train_loss, correct, processed = 0, 0, 0\n",
        "        # Train with progress bar\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(pbar, 1):\n",
        "            # get samples and move to device\n",
        "            data, target = data.to(self.device), target.to(self.device)\n",
        "            # Initialize optimizer\n",
        "            self.optimizer.zero_grad()\n",
        "            # Prediction\n",
        "            output = self.model(data)\n",
        "            # Calculate loss\n",
        "            loss = self.F.nll_loss(output, target)\n",
        "            # Backpropagation\n",
        "            loss.backward()\n",
        "            # Gradient clipping to stabilize higher LR OneCycle swings\n",
        "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=2.0)\n",
        "            self.optimizer.step()\n",
        "            # Per-batch scheduler stepping (e.g., OneCycleLR) if attribute present\n",
        "            if hasattr(self, 'scheduler') and getattr(self.scheduler, 'batch_step', False):\n",
        "                self.scheduler.step()\n",
        "            # -----------------------------\n",
        "            # Accumulate loss and calculate accuracy\n",
        "            train_loss += loss.item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            batch_correct = pred.eq(target.view_as(pred)).sum().item()\n",
        "            correct += batch_correct\n",
        "            processed += len(data)\n",
        "\n",
        "            # Calculate current metrics\n",
        "            current_loss = train_loss / processed\n",
        "            current_accuracy = 100. * correct / processed\n",
        "\n",
        "            # Update progress bar only (add LR peek occasionally)\n",
        "            if hasattr(self, 'scheduler') and getattr(self.scheduler, 'batch_step', False):\n",
        "                current_lr = self.scheduler.get_last_lr()[0]\n",
        "                status = f\"Train Loss={current_loss:.4f} Acc={current_accuracy:.2f}% LR={current_lr:.4f}\"\n",
        "            else:\n",
        "                status = f\"Train Loss={current_loss:.4f} Accuracy={current_accuracy:.2f}%\"\n",
        "            pbar.set_description(desc=status)\n",
        "\n",
        "        # Final epoch-level logging for training metrics\n",
        "        epoch_accuracy = 100. * correct / len(self.train_loader.dataset)\n",
        "        logging.info(\n",
        "            f'Epoch {epoch:02d}/{self.epochs}: Train set final results: Average loss: {train_loss:.4f}, '\n",
        "            f'Accuracy: {correct}/{len(self.train_loader.dataset)} ({epoch_accuracy:.2f}%)'\n",
        "        )\n",
        "        return epoch_accuracy\n",
        "\n",
        "    def test(self, model, device, test_loader, criterion,epoch):\n",
        "        self.model.eval()\n",
        "        test_loss, correct = 0, 0\n",
        "        # Test with progress bar\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pbar = tqdm(self.test_loader, desc=\"Testing\", leave=True)\n",
        "            for batch_idx, (data, target) in enumerate(pbar, 1):\n",
        "                data, target = data.to(self.device), target.to(self.device)\n",
        "                output = self.model(data)\n",
        "                test_loss += self.F.nll_loss(output, target, reduction='sum').item()\n",
        "                pred = output.argmax(dim=1, keepdim=True)\n",
        "                batch_correct = pred.eq(target.view_as(pred)).sum().item()\n",
        "                correct += batch_correct\n",
        "\n",
        "                # Calculate current metrics\n",
        "                current_loss = test_loss / (batch_idx * len(data))\n",
        "                current_accuracy = 100. * correct / (batch_idx * len(data))\n",
        "\n",
        "                # Update progress bar only\n",
        "                status = f\"Test Loss={current_loss:.4f} Accuracy={current_accuracy:.2f}%\"\n",
        "                pbar.set_description(desc=status)\n",
        "\n",
        "        test_loss /= len(self.test_loader.dataset)\n",
        "        acc = 100. * correct / len(self.test_loader.dataset)\n",
        "        logging.info(f'Epoch {epoch:02d}/{self.epochs}:Test set final results: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(self.test_loader.dataset)} ({acc:.2f}%)')\n",
        "        return acc\n",
        "\n",
        "    def do_training(self,epoch):\n",
        "        return self.train(self.model, self.device, self.train_loader, self.optimizer, self.criterion,epoch)\n",
        "\n",
        "    def do_testing(self,epoch):\n",
        "        return self.test(self.model, self.device, self.test_loader, self.criterion,epoch)\n",
        "\n",
        "    def run_epoch(self):\n",
        "        logging.info(f\"Training model for {self.epochs} epochs\")\n",
        "        for epoch in range(1, self.epochs+1):\n",
        "            train_acc = self.do_training(epoch=epoch)\n",
        "            test_acc = self.do_testing(epoch=epoch)\n",
        "            # Epoch-level scheduler step only if not using per-batch scheduler\n",
        "            if hasattr(self.scheduler, 'batch_step') and not getattr(self.scheduler, 'batch_step'):\n",
        "                self.scheduler.step()\n",
        "            elif not hasattr(self.scheduler, 'batch_step'):\n",
        "                # Legacy schedulers\n",
        "                try:\n",
        "                    self.scheduler.step()\n",
        "                except Exception:\n",
        "                    pass\n",
        "            self.train_acc_list.append(train_acc)\n",
        "            self.test_acc_list.append(test_acc)\n",
        "\n",
        "            #logging.info(f\"Epoch {epoch:02d}/{self.epochs}: Train={train_acc:.2f}%, Test={test_acc:.2f}%, LR={self.scheduler.get_last_lr()[0]:.6f}\")\n",
        "\n",
        "    def plot_results(self):\n",
        "        plt.plot(self.train_acc_list, label='Train Acc')\n",
        "        plt.plot(self.test_acc_list, label='Test Acc')\n",
        "        plt.legend()\n",
        "        plt.title(\"Training vs Test Accuracy\")\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a6d10375",
      "metadata": {
        "id": "a6d10375"
      },
      "outputs": [],
      "source": [
        "# ================================\n",
        "# summarizer.py - Model Summary & Checks\n",
        "# ================================\n",
        "import torch.nn as nn\n",
        "from torchsummary import summary\n",
        "\n",
        "# -----------------------------\n",
        "# 8. Model Architecture Checks\n",
        "# -----------------------------\n",
        "def model_checks(model):\n",
        "    import logging\n",
        "\n",
        "    logging.info('--- Model Architecture Checks ---')\n",
        "    # Total Parameter Count\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    logging.info(f'Total Parameters: {total_params:,}')\n",
        "    logging.info(f'Trainable Parameters: {trainable_params:,}\\n')\n",
        "\n",
        "    logging.info('Layer-wise Parameter Details (in model order):')\n",
        "    logging.info('-'*100)\n",
        "\n",
        "    def get_layer_details(module):\n",
        "        details = ''\n",
        "        if isinstance(module, nn.Conv2d):\n",
        "            details = (f'Convolution: {module.in_channels}->{module.out_channels} channels, '\n",
        "                      f'kernel {module.kernel_size}, stride {module.stride}, padding {module.padding}, '\n",
        "                      f'groups {module.groups}, bias {module.bias is not None}')\n",
        "        elif isinstance(module, nn.BatchNorm2d):\n",
        "            details = f'BatchNorm: {module.num_features} features, eps={module.eps}, momentum={module.momentum}'\n",
        "        elif isinstance(module, nn.ReLU):\n",
        "            details = 'Activation: ReLU'\n",
        "        elif isinstance(module, nn.ReLU6):\n",
        "            details = 'Activation: ReLU6'\n",
        "        elif isinstance(module, nn.LeakyReLU):\n",
        "            details = f'Activation: LeakyReLU (negative_slope={module.negative_slope})'\n",
        "        elif isinstance(module, nn.MaxPool2d):\n",
        "            details = f'MaxPool: kernel {module.kernel_size}, stride {module.stride}, padding {module.padding}'\n",
        "        elif isinstance(module, nn.AvgPool2d):\n",
        "            details = f'AvgPool: kernel {module.kernel_size}, stride {module.stride}, padding {module.padding}'\n",
        "        elif isinstance(module, nn.AdaptiveAvgPool2d):\n",
        "            details = f'AdaptiveAvgPool: output size {module.output_size}'\n",
        "        elif isinstance(module, nn.Dropout):\n",
        "            details = f'Dropout: probability {module.p}'\n",
        "        elif isinstance(module, nn.Dropout2d):\n",
        "            details = f'Dropout2d: probability {module.p}'\n",
        "        elif isinstance(module, nn.Linear):\n",
        "            details = f'Linear: {module.in_features}->{module.out_features}, bias {module.bias is not None}'\n",
        "        elif isinstance(module, nn.Flatten):\n",
        "            details = 'Flatten'\n",
        "        return details\n",
        "\n",
        "    # Get layers in order as defined in model\n",
        "    for name, module in model.named_children():\n",
        "        if isinstance(module, nn.Sequential):\n",
        "            logging.info(f\"\\nBlock: {name} (Sequential)\")\n",
        "            for subname, submodule in module.named_children():\n",
        "                layer_name = f'{name}.{subname} ({submodule.__class__.__name__})'\n",
        "                layer_params = sum(p.numel() for p in submodule.parameters())\n",
        "                details = get_layer_details(submodule)\n",
        "                logging.info(f'  {layer_name:50} | Params: {layer_params:6,d} | {details}')\n",
        "        else:\n",
        "            layer_name = f'{name} ({module.__class__.__name__})'\n",
        "            layer_params = sum(p.numel() for p in module.parameters())\n",
        "            details = get_layer_details(module)\n",
        "            logging.info(f'  {layer_name:50} | Params: {layer_params:6,d} | {details}')\n",
        "\n",
        "    logging.info('-'*100)\n",
        "    logging.info('\\nLayer Type Summary:')\n",
        "\n",
        "    # Count all layer types\n",
        "    layer_types = {\n",
        "        'Conv2d': [m for m in model.modules() if isinstance(m, nn.Conv2d)],\n",
        "        'BatchNorm2d': [m for m in model.modules() if isinstance(m, nn.BatchNorm2d)],\n",
        "        'ReLU': [m for m in model.modules() if isinstance(m, (nn.ReLU, nn.ReLU6))],\n",
        "        'LeakyReLU': [m for m in model.modules() if isinstance(m, nn.LeakyReLU)],\n",
        "        'MaxPool2d': [m for m in model.modules() if isinstance(m, nn.MaxPool2d)],\n",
        "        'AvgPool2d': [m for m in model.modules() if isinstance(m, nn.AvgPool2d)],\n",
        "        'AdaptiveAvgPool2d': [m for m in model.modules() if isinstance(m, nn.AdaptiveAvgPool2d)],\n",
        "        'Dropout': [m for m in model.modules() if isinstance(m, nn.Dropout)],\n",
        "        'Dropout2d': [m for m in model.modules() if isinstance(m, nn.Dropout2d)],\n",
        "        'Linear': [m for m in model.modules() if isinstance(m, nn.Linear)],\n",
        "        'Flatten': [m for m in model.modules() if isinstance(m, nn.Flatten)]\n",
        "    }\n",
        "\n",
        "    for layer_type, layers in layer_types.items():\n",
        "        if layers:  # Only show if there are layers of this type\n",
        "            logging.info(f'{layer_type:20} layers used: {len(layers):3d}')\n",
        "\n",
        "    logging.info('-'*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "93b46b91",
      "metadata": {
        "id": "93b46b91"
      },
      "outputs": [],
      "source": [
        "# ================================\n",
        "# receptive_field_calculator.py - RF Calculation\n",
        "# ================================\n",
        "def calculate_receptive_field(model):\n",
        "    \"\"\"\n",
        "    Calculate receptive field for each layer in the model.\n",
        "    Formula: RF_new = RF_previous + (kernel_size - 1) * dilation for stride=1\n",
        "             RF_new = RF_previous * stride + (kernel_size - 1) * dilation for stride>1\n",
        "    \"\"\"\n",
        "    rf = 1  # Starting receptive field (single pixel)\n",
        "    print(\"Layer-by-layer receptive field calculation:\")\n",
        "    print(f\"Input: RF = {rf}\")\n",
        "\n",
        "    # C1 block\n",
        "    print(\"\\nC1 Block:\")\n",
        "    # Conv2d(3, 8, 3, padding=1)\n",
        "    rf = rf + (3 - 1) * 1\n",
        "    print(f\"Conv2d(3->8, 3x3, p=1): RF = {rf}\")\n",
        "\n",
        "    # Conv2d(8, 16, 3, padding=1)\n",
        "    rf = rf + (3 - 1) * 1\n",
        "    print(f\"Conv2d(8->16, 3x3, p=1): RF = {rf}\")\n",
        "\n",
        "    # Conv2d(16, 32, 3, padding=1)\n",
        "    rf = rf + (3 - 1) * 1\n",
        "    print(f\"Conv2d(16->32, 3x3, p=1): RF = {rf}\")\n",
        "\n",
        "    # C2 block\n",
        "    print(\"\\nC2 Block:\")\n",
        "    # Conv2d(32, 32, 3, padding=1, dilation=1)\n",
        "    rf = rf + (3 - 1) * 1\n",
        "    print(f\"Conv2d(32->32, 3x3, p=1, d=1): RF = {rf}\")\n",
        "\n",
        "    # Conv2d(32, 32, 3, padding=2, dilation=2)\n",
        "    rf = rf + (3 - 1) * 2\n",
        "    print(f\"Conv2d(32->32, 3x3, p=2, d=2): RF = {rf}\")\n",
        "\n",
        "    # Conv2d(32, 32, 3, padding=4, dilation=4)\n",
        "    rf = rf + (3 - 1) * 4\n",
        "    print(f\"Conv2d(32->32, 3x3, p=4, d=4): RF = {rf}\")\n",
        "\n",
        "    # C3 block\n",
        "    print(\"\\nC3 Block:\")\n",
        "    # DepthwiseSeparableConv depthwise: Conv2d(32, 32, 3, stride=2, padding=1, groups=32)\n",
        "    rf = rf * 2 + (3 - 1) * 1\n",
        "    print(f\"DepthwiseConv(32->32, 3x3, s=2, p=1): RF = {rf}\")\n",
        "\n",
        "    # Pointwise doesn't change RF\n",
        "    print(f\"PointwiseConv(32->64, 1x1): RF = {rf} (unchanged)\")\n",
        "\n",
        "    # Conv2d(64, 64, 3, padding=1)\n",
        "    rf = rf + (3 - 1) * 1\n",
        "    print(f\"Conv2d(64->64, 3x3, p=1): RF = {rf}\")\n",
        "\n",
        "    # C4 block\n",
        "    print(\"\\nC4 Block:\")\n",
        "    # Conv2d(64, 128, 3, stride=2, padding=1)\n",
        "    rf = rf * 2 + (3 - 1) * 1\n",
        "    print(f\"Conv2d(64->128, 3x3, s=2, p=1): RF = {rf}\")\n",
        "\n",
        "    # GAP doesn't change RF\n",
        "    print(f\"AdaptiveAvgPool2d(1): RF = {rf} (unchanged)\")\n",
        "\n",
        "    print(f\"\\nFinal receptive field: {rf} x {rf} pixels\")\n",
        "    return rf\n",
        "\n",
        "def count_parameters(model):\n",
        "    \"\"\"Count total parameters in the model\"\"\"\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(\"\\nModel Parameters:\")\n",
        "    print(f\"Total parameters: {total_params:,}\")\n",
        "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "    return total_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "dd6510dd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "dd6510dd",
        "outputId": "af69c84b-d8e8-4d03-b876-fa8b0efa2ccf"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3418265308.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3418265308.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# Initialize logging only in the main process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0msetup_logging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_to_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mparams_check\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter 1 for params check only, 0 for full training/testing: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mmain_i\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_check\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams_check\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "# ================================\n",
        "# main.py - Main Training Orchestration\n",
        "# ================================\n",
        "class get_model:\n",
        "    def __init__(self,device=None):\n",
        "        self.device = device if device else self.get_device()\n",
        "        self.model_obj = self.get_model()\n",
        "        self.model_config = self.get_config()\n",
        "\n",
        "    def get_device(self):\n",
        "        return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def get_model(self):\n",
        "        return Net().to(self.device)\n",
        "\n",
        "    def get_config(self):\n",
        "        return set_config_v0().setup(self.model_obj)\n",
        "\n",
        "def main_i(params_check=1):\n",
        "    logging.info(\"Setting up for model\")\n",
        "    model = get_model(device=None)\n",
        "    # Capture printed summary into logs\n",
        "    import io\n",
        "    import contextlib\n",
        "    with io.StringIO() as buf, contextlib.redirect_stdout(buf):\n",
        "        summary(model.model_obj, input_size=(3, 32, 32))\n",
        "        summary_text = buf.getvalue().strip()\n",
        "    if summary_text:\n",
        "        logging.info(\"\\n\" + summary_text)\n",
        "    train_test_instance = train_test_model(model.model_obj,\n",
        "                                          model.device,\n",
        "                                          model.model_config.data_setup_instance.train_loader,\n",
        "                                          model.model_config.data_setup_instance.test_loader,\n",
        "                                          model.model_config.criterion,\n",
        "                                          model.model_config.optimizer,\n",
        "                                          model.model_config.scheduler,\n",
        "                                          model.model_config.epochs)\n",
        "    if (params_check == 0):\n",
        "        train_test_instance.run_epoch()\n",
        "    else:\n",
        "        pass\n",
        "    #train_test_instance.plot_results()\n",
        "    # Capture printed model checks into logs\n",
        "    with io.StringIO() as buf, contextlib.redirect_stdout(buf):\n",
        "        model_checks(model.model_obj)\n",
        "        checks_text = buf.getvalue().strip()\n",
        "    if checks_text:\n",
        "        logging.info(\"\\n\" + checks_text)\n",
        "\n",
        "def main():\n",
        "    # Initialize logging only in the main process\n",
        "    setup_logging(log_to_file=True)\n",
        "    params_check = int(input(\"Enter 1 for params check only, 0 for full training/testing: \"))\n",
        "    main_i(params_check=params_check)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KkivrhJwCWNr"
      },
      "id": "KkivrhJwCWNr"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6322b1c0-2a28-418d-843e-6b01fe1b8208",
        "id": "lN1rAdKECW2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter 1 for params check only, 0 for full training/testing: 0\n",
            "2025-10-02 22:28:19,103 - INFO - Setting up for model\n",
            "2025-10-02 22:28:19,110 - INFO - Model v0 dataloader args: {'batch_size_train': 128, 'batch_size_test': 1000, 'shuffle_train': True, 'shuffle_test': False, 'num_workers': 2, 'pin_memory': True}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "/tmp/ipython-input-2167529188.py:48: UserWarning: Argument(s) 'max_holes, max_height, max_width, min_holes, min_height, min_width, fill_value, mask_fill_value' are not valid for transform CoarseDropout\n",
            "  A.CoarseDropout(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:28:20,683 - INFO - Model v0: OneCycleLR max_lr=0.01 pct_start=0.2 div_factor=10 final_div_factor=100 epochs=15\n",
            "2025-10-02 22:28:20,683 - INFO - Dataloader arguments: {'batch_size_train': 128, 'batch_size_test': 1000, 'shuffle_train': True, 'shuffle_test': False, 'num_workers': 2, 'pin_memory': True}\n",
            "2025-10-02 22:28:20,724 - INFO - \n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 32, 32]             216\n",
            "       BatchNorm2d-2            [-1, 8, 32, 32]              16\n",
            "              ReLU-3            [-1, 8, 32, 32]               0\n",
            "           Dropout-4            [-1, 8, 32, 32]               0\n",
            "            Conv2d-5           [-1, 16, 32, 32]           1,152\n",
            "       BatchNorm2d-6           [-1, 16, 32, 32]              32\n",
            "              ReLU-7           [-1, 16, 32, 32]               0\n",
            "           Dropout-8           [-1, 16, 32, 32]               0\n",
            "            Conv2d-9           [-1, 32, 32, 32]           4,608\n",
            "      BatchNorm2d-10           [-1, 32, 32, 32]              64\n",
            "             ReLU-11           [-1, 32, 32, 32]               0\n",
            "          Dropout-12           [-1, 32, 32, 32]               0\n",
            "           Conv2d-13           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-14           [-1, 32, 32, 32]              64\n",
            "             ReLU-15           [-1, 32, 32, 32]               0\n",
            "          Dropout-16           [-1, 32, 32, 32]               0\n",
            "           Conv2d-17           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-18           [-1, 32, 32, 32]              64\n",
            "             ReLU-19           [-1, 32, 32, 32]               0\n",
            "          Dropout-20           [-1, 32, 32, 32]               0\n",
            "           Conv2d-21           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-22           [-1, 32, 32, 32]              64\n",
            "             ReLU-23           [-1, 32, 32, 32]               0\n",
            "          Dropout-24           [-1, 32, 32, 32]               0\n",
            "           Conv2d-25           [-1, 32, 16, 16]             288\n",
            "      BatchNorm2d-26           [-1, 32, 16, 16]              64\n",
            "           Conv2d-27           [-1, 64, 16, 16]           2,048\n",
            "      BatchNorm2d-28           [-1, 64, 16, 16]             128\n",
            "DepthwiseSeparableConv-29           [-1, 64, 16, 16]               0\n",
            "           Conv2d-30           [-1, 64, 16, 16]          36,864\n",
            "      BatchNorm2d-31           [-1, 64, 16, 16]             128\n",
            "             ReLU-32           [-1, 64, 16, 16]               0\n",
            "          Dropout-33           [-1, 64, 16, 16]               0\n",
            "           Conv2d-34            [-1, 128, 8, 8]          73,728\n",
            "AdaptiveAvgPool2d-35            [-1, 128, 1, 1]               0\n",
            "          Flatten-36                  [-1, 128]               0\n",
            "           Linear-37                   [-1, 10]           1,290\n",
            "================================================================\n",
            "Total params: 148,466\n",
            "Trainable params: 148,466\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.81\n",
            "Params size (MB): 0.57\n",
            "Estimated Total Size (MB): 6.39\n",
            "----------------------------------------------------------------\n",
            "2025-10-02 22:28:20,725 - INFO - Training model for 15 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0154 Acc=24.35% LR=0.0033: 100%|| 391/391 [00:22<00:00, 17.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:28:42,772 - INFO - Epoch 01/15: Train set final results: Average loss: 768.4059, Accuracy: 12176/50000 (24.35%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=1.7024 Accuracy=31.12%: 100%|| 10/10 [00:01<00:00,  5.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:28:44,479 - INFO - Epoch 01/15:Test set final results: Average loss: 1.7024, Accuracy: 3112/10000 (31.12%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0124 Acc=39.06% LR=0.0078: 100%|| 391/391 [00:21<00:00, 18.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:29:05,698 - INFO - Epoch 02/15: Train set final results: Average loss: 618.5986, Accuracy: 19528/50000 (39.06%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=1.4052 Accuracy=47.93%: 100%|| 10/10 [00:02<00:00,  4.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:29:07,960 - INFO - Epoch 02/15:Test set final results: Average loss: 1.4052, Accuracy: 4793/10000 (47.93%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0105 Acc=50.17% LR=0.0100: 100%|| 391/391 [00:21<00:00, 18.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:29:29,504 - INFO - Epoch 03/15: Train set final results: Average loss: 523.0820, Accuracy: 25084/50000 (50.17%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=1.2297 Accuracy=54.69%: 100%|| 10/10 [00:01<00:00,  6.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:29:31,094 - INFO - Epoch 03/15:Test set final results: Average loss: 1.2297, Accuracy: 5469/10000 (54.69%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0092 Acc=56.84% LR=0.0098: 100%|| 391/391 [00:22<00:00, 17.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:29:53,915 - INFO - Epoch 04/15: Train set final results: Average loss: 462.0059, Accuracy: 28422/50000 (56.84%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=1.0360 Accuracy=62.31%: 100%|| 10/10 [00:01<00:00,  6.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:29:55,494 - INFO - Epoch 04/15:Test set final results: Average loss: 1.0360, Accuracy: 6231/10000 (62.31%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0085 Acc=60.62% LR=0.0093: 100%|| 391/391 [00:23<00:00, 16.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:30:19,105 - INFO - Epoch 05/15: Train set final results: Average loss: 423.8401, Accuracy: 30309/50000 (60.62%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=1.0187 Accuracy=63.71%: 100%|| 10/10 [00:01<00:00,  6.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:30:20,684 - INFO - Epoch 05/15:Test set final results: Average loss: 1.0187, Accuracy: 6371/10000 (63.71%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0080 Acc=63.30% LR=0.0085: 100%|| 391/391 [00:22<00:00, 17.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:30:43,103 - INFO - Epoch 06/15: Train set final results: Average loss: 397.6592, Accuracy: 31648/50000 (63.30%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.9465 Accuracy=65.90%: 100%|| 10/10 [00:01<00:00,  6.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:30:44,678 - INFO - Epoch 06/15:Test set final results: Average loss: 0.9465, Accuracy: 6590/10000 (65.90%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0075 Acc=65.29% LR=0.0075: 100%|| 391/391 [00:22<00:00, 17.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:31:06,939 - INFO - Epoch 07/15: Train set final results: Average loss: 377.3529, Accuracy: 32643/50000 (65.29%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.9542 Accuracy=66.25%: 100%|| 10/10 [00:01<00:00,  6.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:31:08,495 - INFO - Epoch 07/15:Test set final results: Average loss: 0.9542, Accuracy: 6625/10000 (66.25%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0072 Acc=66.94% LR=0.0063: 100%|| 391/391 [00:22<00:00, 17.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:31:30,599 - INFO - Epoch 08/15: Train set final results: Average loss: 359.0284, Accuracy: 33471/50000 (66.94%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.8503 Accuracy=70.29%: 100%|| 10/10 [00:01<00:00,  5.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:31:32,366 - INFO - Epoch 08/15:Test set final results: Average loss: 0.8503, Accuracy: 7029/10000 (70.29%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0068 Acc=68.51% LR=0.0050: 100%|| 391/391 [00:21<00:00, 18.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:31:53,793 - INFO - Epoch 09/15: Train set final results: Average loss: 341.0438, Accuracy: 34257/50000 (68.51%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.8262 Accuracy=70.48%: 100%|| 10/10 [00:02<00:00,  4.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:31:55,854 - INFO - Epoch 09/15:Test set final results: Average loss: 0.8262, Accuracy: 7048/10000 (70.48%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0065 Acc=70.29% LR=0.0037: 100%|| 391/391 [00:21<00:00, 17.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:32:17,715 - INFO - Epoch 10/15: Train set final results: Average loss: 326.6047, Accuracy: 35147/50000 (70.29%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.7987 Accuracy=71.82%: 100%|| 10/10 [00:01<00:00,  6.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:32:19,379 - INFO - Epoch 10/15:Test set final results: Average loss: 0.7987, Accuracy: 7182/10000 (71.82%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0063 Acc=71.32% LR=0.0025: 100%|| 391/391 [00:22<00:00, 17.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:32:41,889 - INFO - Epoch 11/15: Train set final results: Average loss: 314.6136, Accuracy: 35659/50000 (71.32%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.7214 Accuracy=74.69%: 100%|| 10/10 [00:01<00:00,  6.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:32:43,483 - INFO - Epoch 11/15:Test set final results: Average loss: 0.7214, Accuracy: 7469/10000 (74.69%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0060 Acc=72.63% LR=0.0015: 100%|| 391/391 [00:22<00:00, 17.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:33:06,151 - INFO - Epoch 12/15: Train set final results: Average loss: 300.9645, Accuracy: 36317/50000 (72.63%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.7147 Accuracy=74.81%: 100%|| 10/10 [00:02<00:00,  4.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:33:08,473 - INFO - Epoch 12/15:Test set final results: Average loss: 0.7147, Accuracy: 7481/10000 (74.81%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0059 Acc=73.42% LR=0.0007: 100%|| 391/391 [00:22<00:00, 17.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:33:31,173 - INFO - Epoch 13/15: Train set final results: Average loss: 293.4296, Accuracy: 36710/50000 (73.42%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.6682 Accuracy=76.38%: 100%|| 10/10 [00:01<00:00,  6.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:33:32,792 - INFO - Epoch 13/15:Test set final results: Average loss: 0.6682, Accuracy: 7638/10000 (76.38%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0057 Acc=74.39% LR=0.0002: 100%|| 391/391 [00:22<00:00, 17.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:33:55,486 - INFO - Epoch 14/15: Train set final results: Average loss: 283.5937, Accuracy: 37196/50000 (74.39%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.6586 Accuracy=77.09%: 100%|| 10/10 [00:01<00:00,  6.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:33:57,069 - INFO - Epoch 14/15:Test set final results: Average loss: 0.6586, Accuracy: 7709/10000 (77.09%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0056 Acc=74.55% LR=0.0000: 100%|| 391/391 [00:22<00:00, 17.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:34:19,748 - INFO - Epoch 15/15: Train set final results: Average loss: 279.6953, Accuracy: 37274/50000 (74.55%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.6558 Accuracy=77.01%: 100%|| 10/10 [00:01<00:00,  5.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:34:21,426 - INFO - Epoch 15/15:Test set final results: Average loss: 0.6558, Accuracy: 7701/10000 (77.01%)\n",
            "2025-10-02 22:34:21,431 - INFO - \n",
            "2025-10-02 22:34:21,426 - INFO - --- Model Architecture Checks ---\n",
            "2025-10-02 22:34:21,427 - INFO - Total Parameters: 148,466\n",
            "2025-10-02 22:34:21,427 - INFO - Trainable Parameters: 148,466\n",
            "\n",
            "2025-10-02 22:34:21,427 - INFO - Layer-wise Parameter Details (in model order):\n",
            "2025-10-02 22:34:21,427 - INFO - ----------------------------------------------------------------------------------------------------\n",
            "2025-10-02 22:34:21,427 - INFO - \n",
            "Block: c1 (Sequential)\n",
            "2025-10-02 22:34:21,428 - INFO -   c1.0 (Conv2d)                                      | Params:    216 | Convolution: 3->8 channels, kernel (3, 3), stride (1, 1), padding (1, 1), groups 1, bias False\n",
            "2025-10-02 22:34:21,428 - INFO -   c1.1 (BatchNorm2d)                                 | Params:     16 | BatchNorm: 8 features, eps=1e-05, momentum=0.1\n",
            "2025-10-02 22:34:21,428 - INFO -   c1.2 (ReLU)                                        | Params:      0 | Activation: ReLU\n",
            "2025-10-02 22:34:21,428 - INFO -   c1.3 (Dropout)                                     | Params:      0 | Dropout: probability 0.05\n",
            "2025-10-02 22:34:21,428 - INFO -   c1.4 (Conv2d)                                      | Params:  1,152 | Convolution: 8->16 channels, kernel (3, 3), stride (1, 1), padding (1, 1), groups 1, bias False\n",
            "2025-10-02 22:34:21,428 - INFO -   c1.5 (BatchNorm2d)                                 | Params:     32 | BatchNorm: 16 features, eps=1e-05, momentum=0.1\n",
            "2025-10-02 22:34:21,428 - INFO -   c1.6 (ReLU)                                        | Params:      0 | Activation: ReLU\n",
            "2025-10-02 22:34:21,428 - INFO -   c1.7 (Dropout)                                     | Params:      0 | Dropout: probability 0.05\n",
            "2025-10-02 22:34:21,428 - INFO -   c1.8 (Conv2d)                                      | Params:  4,608 | Convolution: 16->32 channels, kernel (3, 3), stride (1, 1), padding (1, 1), groups 1, bias False\n",
            "2025-10-02 22:34:21,429 - INFO -   c1.9 (BatchNorm2d)                                 | Params:     64 | BatchNorm: 32 features, eps=1e-05, momentum=0.1\n",
            "2025-10-02 22:34:21,429 - INFO -   c1.10 (ReLU)                                       | Params:      0 | Activation: ReLU\n",
            "2025-10-02 22:34:21,429 - INFO -   c1.11 (Dropout)                                    | Params:      0 | Dropout: probability 0.05\n",
            "2025-10-02 22:34:21,429 - INFO - \n",
            "Block: c2 (Sequential)\n",
            "2025-10-02 22:34:21,429 - INFO -   c2.0 (Conv2d)                                      | Params:  9,216 | Convolution: 32->32 channels, kernel (3, 3), stride (1, 1), padding (1, 1), groups 1, bias False\n",
            "2025-10-02 22:34:21,429 - INFO -   c2.1 (BatchNorm2d)                                 | Params:     64 | BatchNorm: 32 features, eps=1e-05, momentum=0.1\n",
            "2025-10-02 22:34:21,429 - INFO -   c2.2 (ReLU)                                        | Params:      0 | Activation: ReLU\n",
            "2025-10-02 22:34:21,429 - INFO -   c2.3 (Dropout)                                     | Params:      0 | Dropout: probability 0.05\n",
            "2025-10-02 22:34:21,429 - INFO -   c2.4 (Conv2d)                                      | Params:  9,216 | Convolution: 32->32 channels, kernel (3, 3), stride (1, 1), padding (2, 2), groups 1, bias False\n",
            "2025-10-02 22:34:21,429 - INFO -   c2.5 (BatchNorm2d)                                 | Params:     64 | BatchNorm: 32 features, eps=1e-05, momentum=0.1\n",
            "2025-10-02 22:34:21,429 - INFO -   c2.6 (ReLU)                                        | Params:      0 | Activation: ReLU\n",
            "2025-10-02 22:34:21,429 - INFO -   c2.7 (Dropout)                                     | Params:      0 | Dropout: probability 0.05\n",
            "2025-10-02 22:34:21,429 - INFO -   c2.8 (Conv2d)                                      | Params:  9,216 | Convolution: 32->32 channels, kernel (3, 3), stride (1, 1), padding (4, 4), groups 1, bias False\n",
            "2025-10-02 22:34:21,429 - INFO -   c2.9 (BatchNorm2d)                                 | Params:     64 | BatchNorm: 32 features, eps=1e-05, momentum=0.1\n",
            "2025-10-02 22:34:21,429 - INFO -   c2.10 (ReLU)                                       | Params:      0 | Activation: ReLU\n",
            "2025-10-02 22:34:21,429 - INFO -   c2.11 (Dropout)                                    | Params:      0 | Dropout: probability 0.05\n",
            "2025-10-02 22:34:21,429 - INFO - \n",
            "Block: c3 (Sequential)\n",
            "2025-10-02 22:34:21,429 - INFO -   c3.0 (DepthwiseSeparableConv)                      | Params:  2,528 | \n",
            "2025-10-02 22:34:21,429 - INFO -   c3.1 (Conv2d)                                      | Params: 36,864 | Convolution: 64->64 channels, kernel (3, 3), stride (1, 1), padding (1, 1), groups 1, bias False\n",
            "2025-10-02 22:34:21,430 - INFO -   c3.2 (BatchNorm2d)                                 | Params:    128 | BatchNorm: 64 features, eps=1e-05, momentum=0.1\n",
            "2025-10-02 22:34:21,430 - INFO -   c3.3 (ReLU)                                        | Params:      0 | Activation: ReLU\n",
            "2025-10-02 22:34:21,430 - INFO -   c3.4 (Dropout)                                     | Params:      0 | Dropout: probability 0.05\n",
            "2025-10-02 22:34:21,430 - INFO - \n",
            "Block: c4 (Sequential)\n",
            "2025-10-02 22:34:21,430 - INFO -   c4.0 (Conv2d)                                      | Params: 73,728 | Convolution: 64->128 channels, kernel (3, 3), stride (2, 2), padding (1, 1), groups 1, bias False\n",
            "2025-10-02 22:34:21,430 - INFO -   c4.1 (AdaptiveAvgPool2d)                           | Params:      0 | AdaptiveAvgPool: output size 1\n",
            "2025-10-02 22:34:21,430 - INFO -   c4.2 (Flatten)                                     | Params:      0 | Flatten\n",
            "2025-10-02 22:34:21,430 - INFO -   c4.3 (Linear)                                      | Params:  1,290 | Linear: 128->10, bias True\n",
            "2025-10-02 22:34:21,430 - INFO - ----------------------------------------------------------------------------------------------------\n",
            "2025-10-02 22:34:21,430 - INFO - \n",
            "Layer Type Summary:\n",
            "2025-10-02 22:34:21,430 - INFO - Conv2d               layers used:  10\n",
            "2025-10-02 22:34:21,430 - INFO - BatchNorm2d          layers used:   9\n",
            "2025-10-02 22:34:21,430 - INFO - ReLU                 layers used:   7\n",
            "2025-10-02 22:34:21,430 - INFO - AdaptiveAvgPool2d    layers used:   1\n",
            "2025-10-02 22:34:21,431 - INFO - Dropout              layers used:   7\n",
            "2025-10-02 22:34:21,431 - INFO - Linear               layers used:   1\n",
            "2025-10-02 22:34:21,431 - INFO - Flatten              layers used:   1\n",
            "2025-10-02 22:34:21,431 - INFO - ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ================================\n",
        "# main.py - Main Training Orchestration\n",
        "# ================================\n",
        "class get_model:\n",
        "    def __init__(self,device=None):\n",
        "        self.device = device if device else self.get_device()\n",
        "        self.model_obj = self.get_model()\n",
        "        self.model_config = self.get_config()\n",
        "\n",
        "    def get_device(self):\n",
        "        return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def get_model(self):\n",
        "        return Net().to(self.device)\n",
        "\n",
        "    def get_config(self):\n",
        "        return set_config_v0().setup(self.model_obj)\n",
        "\n",
        "def main_i(params_check=1):\n",
        "    logging.info(\"Setting up for model\")\n",
        "    model = get_model(device=None)\n",
        "    # Capture printed summary into logs\n",
        "    import io\n",
        "    import contextlib\n",
        "    with io.StringIO() as buf, contextlib.redirect_stdout(buf):\n",
        "        summary(model.model_obj, input_size=(3, 32, 32))\n",
        "        summary_text = buf.getvalue().strip()\n",
        "    if summary_text:\n",
        "        logging.info(\"\\n\" + summary_text)\n",
        "    train_test_instance = train_test_model(model.model_obj,\n",
        "                                          model.device,\n",
        "                                          model.model_config.data_setup_instance.train_loader,\n",
        "                                          model.model_config.data_setup_instance.test_loader,\n",
        "                                          model.model_config.criterion,\n",
        "                                          model.model_config.optimizer,\n",
        "                                          model.model_config.scheduler,\n",
        "                                          model.model_config.epochs)\n",
        "    if (params_check == 0):\n",
        "        train_test_instance.run_epoch()\n",
        "    else:\n",
        "        pass\n",
        "    #train_test_instance.plot_results()\n",
        "    # Capture printed model checks into logs\n",
        "    with io.StringIO() as buf, contextlib.redirect_stdout(buf):\n",
        "        model_checks(model.model_obj)\n",
        "        checks_text = buf.getvalue().strip()\n",
        "    if checks_text:\n",
        "        logging.info(\"\\n\" + checks_text)\n",
        "\n",
        "def main():\n",
        "    # Initialize logging only in the main process\n",
        "    setup_logging(log_to_file=True)\n",
        "    params_check = int(input(\"Enter 1 for params check only, 0 for full training/testing: \"))\n",
        "    main_i(params_check=params_check)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "id": "lN1rAdKECW2e"
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# main.py - Main Training Orchestration\n",
        "# ================================\n",
        "class get_model:\n",
        "    def __init__(self,device=None):\n",
        "        self.device = device if device else self.get_device()\n",
        "        self.model_obj = self.get_model()\n",
        "        self.model_config = self.get_config()\n",
        "\n",
        "    def get_device(self):\n",
        "        return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def get_model(self):\n",
        "        return Net().to(self.device)\n",
        "\n",
        "    def get_config(self):\n",
        "        return set_config_v0().setup(self.model_obj)\n",
        "\n",
        "def main_i(params_check=1):\n",
        "    logging.info(\"Setting up for model\")\n",
        "    model = get_model(device=None)\n",
        "    # Capture printed summary into logs\n",
        "    import io\n",
        "    import contextlib\n",
        "    with io.StringIO() as buf, contextlib.redirect_stdout(buf):\n",
        "        summary(model.model_obj, input_size=(3, 32, 32))\n",
        "        summary_text = buf.getvalue().strip()\n",
        "    if summary_text:\n",
        "        logging.info(\"\\n\" + summary_text)\n",
        "    train_test_instance = train_test_model(model.model_obj,\n",
        "                                          model.device,\n",
        "                                          model.model_config.data_setup_instance.train_loader,\n",
        "                                          model.model_config.data_setup_instance.test_loader,\n",
        "                                          model.model_config.criterion,\n",
        "                                          model.model_config.optimizer,\n",
        "                                          model.model_config.scheduler,\n",
        "                                          model.model_config.epochs)\n",
        "    if (params_check == 0):\n",
        "        train_test_instance.run_epoch()\n",
        "    else:\n",
        "        pass\n",
        "    #train_test_instance.plot_results()\n",
        "    # Capture printed model checks into logs\n",
        "    with io.StringIO() as buf, contextlib.redirect_stdout(buf):\n",
        "        model_checks(model.model_obj)\n",
        "        checks_text = buf.getvalue().strip()\n",
        "    if checks_text:\n",
        "        logging.info(\"\\n\" + checks_text)\n",
        "\n",
        "def main():\n",
        "    # Initialize logging only in the main process\n",
        "    setup_logging(log_to_file=True)\n",
        "    params_check = int(input(\"Enter 1 for params check only, 0 for full training/testing: \"))\n",
        "    main_i(params_check=params_check)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gb-IFkyNIGK5",
        "outputId": "96652ee7-c7f8-4f41-8b30-d10219013bee"
      },
      "id": "gb-IFkyNIGK5",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter 1 for params check only, 0 for full training/testing: 0\n",
            "2025-10-02 22:53:49,846 - INFO - Setting up for model\n",
            "2025-10-02 22:53:49,857 - INFO - Model v0 dataloader args: {'batch_size_train': 128, 'batch_size_test': 1000, 'shuffle_train': True, 'shuffle_test': False, 'num_workers': 2, 'pin_memory': True}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2167529188.py:48: UserWarning: Argument(s) 'max_holes, max_height, max_width, min_holes, min_height, min_width, fill_value, mask_fill_value' are not valid for transform CoarseDropout\n",
            "  A.CoarseDropout(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:53:51,445 - INFO - Model v0: OneCycleLR max_lr=0.01 pct_start=0.2 div_factor=10 final_div_factor=100 epochs=15\n",
            "2025-10-02 22:53:51,446 - INFO - Dataloader arguments: {'batch_size_train': 128, 'batch_size_test': 1000, 'shuffle_train': True, 'shuffle_test': False, 'num_workers': 2, 'pin_memory': True}\n",
            "2025-10-02 22:53:51,452 - INFO - \n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 32, 32]             216\n",
            "       BatchNorm2d-2            [-1, 8, 32, 32]              16\n",
            "              ReLU-3            [-1, 8, 32, 32]               0\n",
            "           Dropout-4            [-1, 8, 32, 32]               0\n",
            "            Conv2d-5           [-1, 16, 32, 32]           1,152\n",
            "       BatchNorm2d-6           [-1, 16, 32, 32]              32\n",
            "              ReLU-7           [-1, 16, 32, 32]               0\n",
            "           Dropout-8           [-1, 16, 32, 32]               0\n",
            "            Conv2d-9           [-1, 32, 32, 32]           4,608\n",
            "      BatchNorm2d-10           [-1, 32, 32, 32]              64\n",
            "             ReLU-11           [-1, 32, 32, 32]               0\n",
            "          Dropout-12           [-1, 32, 32, 32]               0\n",
            "           Conv2d-13           [-1, 32, 30, 30]           9,216\n",
            "      BatchNorm2d-14           [-1, 32, 30, 30]              64\n",
            "             ReLU-15           [-1, 32, 30, 30]               0\n",
            "          Dropout-16           [-1, 32, 30, 30]               0\n",
            "           Conv2d-17           [-1, 32, 30, 30]           9,216\n",
            "      BatchNorm2d-18           [-1, 32, 30, 30]              64\n",
            "             ReLU-19           [-1, 32, 30, 30]               0\n",
            "          Dropout-20           [-1, 32, 30, 30]               0\n",
            "           Conv2d-21           [-1, 32, 28, 28]           9,216\n",
            "      BatchNorm2d-22           [-1, 32, 28, 28]              64\n",
            "             ReLU-23           [-1, 32, 28, 28]               0\n",
            "          Dropout-24           [-1, 32, 28, 28]               0\n",
            "           Conv2d-25           [-1, 32, 14, 14]           9,248\n",
            "      BatchNorm2d-26           [-1, 32, 14, 14]              64\n",
            "             ReLU-27           [-1, 32, 14, 14]               0\n",
            "           Conv2d-28           [-1, 32, 14, 14]             288\n",
            "      BatchNorm2d-29           [-1, 32, 14, 14]              64\n",
            "           Conv2d-30           [-1, 64, 14, 14]           2,048\n",
            "      BatchNorm2d-31           [-1, 64, 14, 14]             128\n",
            "DepthwiseSeparableConv-32           [-1, 64, 14, 14]               0\n",
            "           Conv2d-33           [-1, 64, 14, 14]          36,864\n",
            "      BatchNorm2d-34           [-1, 64, 14, 14]             128\n",
            "             ReLU-35           [-1, 64, 14, 14]               0\n",
            "          Dropout-36           [-1, 64, 14, 14]               0\n",
            "           Conv2d-37          [-1, 128, 14, 14]          73,728\n",
            "AdaptiveAvgPool2d-38            [-1, 128, 1, 1]               0\n",
            "          Flatten-39                  [-1, 128]               0\n",
            "           Linear-40                   [-1, 10]           1,290\n",
            "================================================================\n",
            "Total params: 157,778\n",
            "Trainable params: 157,778\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.38\n",
            "Params size (MB): 0.60\n",
            "Estimated Total Size (MB): 5.99\n",
            "----------------------------------------------------------------\n",
            "2025-10-02 22:53:51,452 - INFO - Training model for 15 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0156 Acc=23.10% LR=0.0033: 100%|| 391/391 [00:21<00:00, 18.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:54:12,677 - INFO - Epoch 01/15: Train set final results: Average loss: 781.3326, Accuracy: 11551/50000 (23.10%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=1.7181 Accuracy=33.99%: 100%|| 10/10 [00:02<00:00,  4.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:54:14,873 - INFO - Epoch 01/15:Test set final results: Average loss: 1.7181, Accuracy: 3399/10000 (33.99%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0122 Acc=41.06% LR=0.0078: 100%|| 391/391 [00:23<00:00, 16.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:54:37,957 - INFO - Epoch 02/15: Train set final results: Average loss: 610.2634, Accuracy: 20528/50000 (41.06%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=1.4122 Accuracy=47.37%: 100%|| 10/10 [00:01<00:00,  6.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:54:39,586 - INFO - Epoch 02/15:Test set final results: Average loss: 1.4122, Accuracy: 4737/10000 (47.37%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0103 Acc=51.46% LR=0.0100: 100%|| 391/391 [00:22<00:00, 17.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:55:01,802 - INFO - Epoch 03/15: Train set final results: Average loss: 516.1983, Accuracy: 25728/50000 (51.46%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=1.1993 Accuracy=56.12%: 100%|| 10/10 [00:01<00:00,  6.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:55:03,437 - INFO - Epoch 03/15:Test set final results: Average loss: 1.1993, Accuracy: 5612/10000 (56.12%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0092 Acc=57.31% LR=0.0098: 100%|| 391/391 [00:22<00:00, 17.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:55:25,980 - INFO - Epoch 04/15: Train set final results: Average loss: 462.0678, Accuracy: 28655/50000 (57.31%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=1.1512 Accuracy=58.89%: 100%|| 10/10 [00:01<00:00,  6.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:55:27,569 - INFO - Epoch 04/15:Test set final results: Average loss: 1.1512, Accuracy: 5889/10000 (58.89%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0086 Acc=60.29% LR=0.0093: 100%|| 391/391 [00:22<00:00, 17.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:55:50,132 - INFO - Epoch 05/15: Train set final results: Average loss: 427.7597, Accuracy: 30144/50000 (60.29%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=1.0688 Accuracy=62.14%: 100%|| 10/10 [00:01<00:00,  6.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:55:51,741 - INFO - Epoch 05/15:Test set final results: Average loss: 1.0688, Accuracy: 6214/10000 (62.14%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0080 Acc=62.72% LR=0.0085: 100%|| 391/391 [00:22<00:00, 17.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:56:14,251 - INFO - Epoch 06/15: Train set final results: Average loss: 401.4008, Accuracy: 31358/50000 (62.72%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.9325 Accuracy=66.78%: 100%|| 10/10 [00:01<00:00,  6.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:56:15,881 - INFO - Epoch 06/15:Test set final results: Average loss: 0.9325, Accuracy: 6678/10000 (66.78%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0076 Acc=65.04% LR=0.0075: 100%|| 391/391 [00:21<00:00, 18.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:56:37,560 - INFO - Epoch 07/15: Train set final results: Average loss: 381.4600, Accuracy: 32521/50000 (65.04%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.9466 Accuracy=66.80%: 100%|| 10/10 [00:02<00:00,  4.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:56:39,941 - INFO - Epoch 07/15:Test set final results: Average loss: 0.9466, Accuracy: 6680/10000 (66.80%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0072 Acc=66.87% LR=0.0063: 100%|| 391/391 [00:21<00:00, 18.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:57:01,429 - INFO - Epoch 08/15: Train set final results: Average loss: 361.3235, Accuracy: 33436/50000 (66.87%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.8526 Accuracy=69.52%: 100%|| 10/10 [00:01<00:00,  5.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:57:03,203 - INFO - Epoch 08/15:Test set final results: Average loss: 0.8526, Accuracy: 6952/10000 (69.52%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0069 Acc=68.25% LR=0.0050: 100%|| 391/391 [00:21<00:00, 17.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:57:25,107 - INFO - Epoch 09/15: Train set final results: Average loss: 346.4174, Accuracy: 34123/50000 (68.25%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.8193 Accuracy=71.12%: 100%|| 10/10 [00:02<00:00,  4.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:57:27,414 - INFO - Epoch 09/15:Test set final results: Average loss: 0.8193, Accuracy: 7112/10000 (71.12%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0066 Acc=70.02% LR=0.0037: 100%|| 391/391 [00:22<00:00, 17.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:57:50,052 - INFO - Epoch 10/15: Train set final results: Average loss: 331.1379, Accuracy: 35008/50000 (70.02%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.7717 Accuracy=72.81%: 100%|| 10/10 [00:01<00:00,  6.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:57:51,648 - INFO - Epoch 10/15:Test set final results: Average loss: 0.7717, Accuracy: 7281/10000 (72.81%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0064 Acc=70.96% LR=0.0025: 100%|| 391/391 [00:22<00:00, 17.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:58:14,145 - INFO - Epoch 11/15: Train set final results: Average loss: 318.8619, Accuracy: 35481/50000 (70.96%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.7331 Accuracy=74.33%: 100%|| 10/10 [00:01<00:00,  6.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:58:15,801 - INFO - Epoch 11/15:Test set final results: Average loss: 0.7331, Accuracy: 7433/10000 (74.33%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0061 Acc=72.50% LR=0.0015: 100%|| 391/391 [00:22<00:00, 17.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:58:38,373 - INFO - Epoch 12/15: Train set final results: Average loss: 306.6767, Accuracy: 36249/50000 (72.50%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.7167 Accuracy=75.07%: 100%|| 10/10 [00:01<00:00,  6.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:58:40,010 - INFO - Epoch 12/15:Test set final results: Average loss: 0.7167, Accuracy: 7507/10000 (75.07%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0059 Acc=73.44% LR=0.0007: 100%|| 391/391 [00:22<00:00, 17.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:59:02,423 - INFO - Epoch 13/15: Train set final results: Average loss: 294.6736, Accuracy: 36720/50000 (73.44%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.6796 Accuracy=76.31%: 100%|| 10/10 [00:01<00:00,  6.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:59:04,035 - INFO - Epoch 13/15:Test set final results: Average loss: 0.6796, Accuracy: 7631/10000 (76.31%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0057 Acc=74.16% LR=0.0002: 100%|| 391/391 [00:21<00:00, 18.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:59:25,611 - INFO - Epoch 14/15: Train set final results: Average loss: 284.8207, Accuracy: 37079/50000 (74.16%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.6624 Accuracy=76.78%: 100%|| 10/10 [00:02<00:00,  4.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:59:27,999 - INFO - Epoch 14/15:Test set final results: Average loss: 0.6624, Accuracy: 7678/10000 (76.78%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0057 Acc=74.68% LR=0.0000: 100%|| 391/391 [00:21<00:00, 17.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:59:49,844 - INFO - Epoch 15/15: Train set final results: Average loss: 282.9829, Accuracy: 37338/50000 (74.68%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.6517 Accuracy=77.33%: 100%|| 10/10 [00:01<00:00,  5.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-02 22:59:51,584 - INFO - Epoch 15/15:Test set final results: Average loss: 0.6517, Accuracy: 7733/10000 (77.33%)\n",
            "2025-10-02 22:59:51,590 - INFO - \n",
            "2025-10-02 22:59:51,584 - INFO - --- Model Architecture Checks ---\n",
            "2025-10-02 22:59:51,585 - INFO - Total Parameters: 157,778\n",
            "2025-10-02 22:59:51,585 - INFO - Trainable Parameters: 157,778\n",
            "\n",
            "2025-10-02 22:59:51,585 - INFO - Layer-wise Parameter Details (in model order):\n",
            "2025-10-02 22:59:51,585 - INFO - ----------------------------------------------------------------------------------------------------\n",
            "2025-10-02 22:59:51,585 - INFO - \n",
            "Block: c1 (Sequential)\n",
            "2025-10-02 22:59:51,585 - INFO -   c1.0 (Conv2d)                                      | Params:    216 | Convolution: 3->8 channels, kernel (3, 3), stride (1, 1), padding (1, 1), groups 1, bias False\n",
            "2025-10-02 22:59:51,586 - INFO -   c1.1 (BatchNorm2d)                                 | Params:     16 | BatchNorm: 8 features, eps=1e-05, momentum=0.1\n",
            "2025-10-02 22:59:51,586 - INFO -   c1.2 (ReLU)                                        | Params:      0 | Activation: ReLU\n",
            "2025-10-02 22:59:51,586 - INFO -   c1.3 (Dropout)                                     | Params:      0 | Dropout: probability 0.05\n",
            "2025-10-02 22:59:51,586 - INFO -   c1.4 (Conv2d)                                      | Params:  1,152 | Convolution: 8->16 channels, kernel (3, 3), stride (1, 1), padding (1, 1), groups 1, bias False\n",
            "2025-10-02 22:59:51,586 - INFO -   c1.5 (BatchNorm2d)                                 | Params:     32 | BatchNorm: 16 features, eps=1e-05, momentum=0.1\n",
            "2025-10-02 22:59:51,586 - INFO -   c1.6 (ReLU)                                        | Params:      0 | Activation: ReLU\n",
            "2025-10-02 22:59:51,587 - INFO -   c1.7 (Dropout)                                     | Params:      0 | Dropout: probability 0.05\n",
            "2025-10-02 22:59:51,587 - INFO -   c1.8 (Conv2d)                                      | Params:  4,608 | Convolution: 16->32 channels, kernel (3, 3), stride (1, 1), padding (1, 1), groups 1, bias False\n",
            "2025-10-02 22:59:51,587 - INFO -   c1.9 (BatchNorm2d)                                 | Params:     64 | BatchNorm: 32 features, eps=1e-05, momentum=0.1\n",
            "2025-10-02 22:59:51,587 - INFO -   c1.10 (ReLU)                                       | Params:      0 | Activation: ReLU\n",
            "2025-10-02 22:59:51,587 - INFO -   c1.11 (Dropout)                                    | Params:      0 | Dropout: probability 0.05\n",
            "2025-10-02 22:59:51,587 - INFO - \n",
            "Block: c2 (Sequential)\n",
            "2025-10-02 22:59:51,587 - INFO -   c2.0 (Conv2d)                                      | Params:  9,216 | Convolution: 32->32 channels, kernel (3, 3), stride (1, 1), padding (0, 0), groups 1, bias False\n",
            "2025-10-02 22:59:51,587 - INFO -   c2.1 (BatchNorm2d)                                 | Params:     64 | BatchNorm: 32 features, eps=1e-05, momentum=0.1\n",
            "2025-10-02 22:59:51,587 - INFO -   c2.2 (ReLU)                                        | Params:      0 | Activation: ReLU\n",
            "2025-10-02 22:59:51,587 - INFO -   c2.3 (Dropout)                                     | Params:      0 | Dropout: probability 0.05\n",
            "2025-10-02 22:59:51,587 - INFO -   c2.4 (Conv2d)                                      | Params:  9,216 | Convolution: 32->32 channels, kernel (3, 3), stride (1, 1), padding (2, 2), groups 1, bias False\n",
            "2025-10-02 22:59:51,587 - INFO -   c2.5 (BatchNorm2d)                                 | Params:     64 | BatchNorm: 32 features, eps=1e-05, momentum=0.1\n",
            "2025-10-02 22:59:51,588 - INFO -   c2.6 (ReLU)                                        | Params:      0 | Activation: ReLU\n",
            "2025-10-02 22:59:51,588 - INFO -   c2.7 (Dropout)                                     | Params:      0 | Dropout: probability 0.05\n",
            "2025-10-02 22:59:51,588 - INFO -   c2.8 (Conv2d)                                      | Params:  9,216 | Convolution: 32->32 channels, kernel (3, 3), stride (1, 1), padding (0, 0), groups 1, bias False\n",
            "2025-10-02 22:59:51,588 - INFO -   c2.9 (BatchNorm2d)                                 | Params:     64 | BatchNorm: 32 features, eps=1e-05, momentum=0.1\n",
            "2025-10-02 22:59:51,588 - INFO -   c2.10 (ReLU)                                       | Params:      0 | Activation: ReLU\n",
            "2025-10-02 22:59:51,588 - INFO -   c2.11 (Dropout)                                    | Params:      0 | Dropout: probability 0.05\n",
            "2025-10-02 22:59:51,588 - INFO - \n",
            "Block: c3 (Sequential)\n",
            "2025-10-02 22:59:51,588 - INFO -   c3.0 (Conv2d)                                      | Params:  9,248 | Convolution: 32->32 channels, kernel (3, 3), stride (2, 2), padding (1, 1), groups 1, bias True\n",
            "2025-10-02 22:59:51,588 - INFO -   c3.1 (BatchNorm2d)                                 | Params:     64 | BatchNorm: 32 features, eps=1e-05, momentum=0.1\n",
            "2025-10-02 22:59:51,588 - INFO -   c3.2 (ReLU)                                        | Params:      0 | Activation: ReLU\n",
            "2025-10-02 22:59:51,588 - INFO -   c3.3 (DepthwiseSeparableConv)                      | Params:  2,528 | \n",
            "2025-10-02 22:59:51,588 - INFO -   c3.4 (Conv2d)                                      | Params: 36,864 | Convolution: 64->64 channels, kernel (3, 3), stride (1, 1), padding (1, 1), groups 1, bias False\n",
            "2025-10-02 22:59:51,588 - INFO -   c3.5 (BatchNorm2d)                                 | Params:    128 | BatchNorm: 64 features, eps=1e-05, momentum=0.1\n",
            "2025-10-02 22:59:51,588 - INFO -   c3.6 (ReLU)                                        | Params:      0 | Activation: ReLU\n",
            "2025-10-02 22:59:51,589 - INFO -   c3.7 (Dropout)                                     | Params:      0 | Dropout: probability 0.05\n",
            "2025-10-02 22:59:51,589 - INFO - \n",
            "Block: c4 (Sequential)\n",
            "2025-10-02 22:59:51,589 - INFO -   c4.0 (Conv2d)                                      | Params: 73,728 | Convolution: 64->128 channels, kernel (3, 3), stride (1, 1), padding (1, 1), groups 1, bias False\n",
            "2025-10-02 22:59:51,589 - INFO -   c4.1 (AdaptiveAvgPool2d)                           | Params:      0 | AdaptiveAvgPool: output size 1\n",
            "2025-10-02 22:59:51,589 - INFO -   c4.2 (Flatten)                                     | Params:      0 | Flatten\n",
            "2025-10-02 22:59:51,589 - INFO -   c4.3 (Linear)                                      | Params:  1,290 | Linear: 128->10, bias True\n",
            "2025-10-02 22:59:51,589 - INFO - ----------------------------------------------------------------------------------------------------\n",
            "2025-10-02 22:59:51,589 - INFO - \n",
            "Layer Type Summary:\n",
            "2025-10-02 22:59:51,590 - INFO - Conv2d               layers used:  11\n",
            "2025-10-02 22:59:51,590 - INFO - BatchNorm2d          layers used:  10\n",
            "2025-10-02 22:59:51,590 - INFO - ReLU                 layers used:   8\n",
            "2025-10-02 22:59:51,590 - INFO - AdaptiveAvgPool2d    layers used:   1\n",
            "2025-10-02 22:59:51,590 - INFO - Dropout              layers used:   7\n",
            "2025-10-02 22:59:51,590 - INFO - Linear               layers used:   1\n",
            "2025-10-02 22:59:51,590 - INFO - Flatten              layers used:   1\n",
            "2025-10-02 22:59:51,590 - INFO - ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# main.py - Main Training Orchestration\n",
        "# ================================\n",
        "class get_model:\n",
        "    def __init__(self,device=None):\n",
        "        self.device = device if device else self.get_device()\n",
        "        self.model_obj = self.get_model()\n",
        "        self.model_config = self.get_config()\n",
        "\n",
        "    def get_device(self):\n",
        "        return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def get_model(self):\n",
        "        return Net().to(self.device)\n",
        "\n",
        "    def get_config(self):\n",
        "        return set_config_v0().setup(self.model_obj)\n",
        "\n",
        "def main_i(params_check=1):\n",
        "    logging.info(\"Setting up for model\")\n",
        "    model = get_model(device=None)\n",
        "    # Capture printed summary into logs\n",
        "    import io\n",
        "    import contextlib\n",
        "    with io.StringIO() as buf, contextlib.redirect_stdout(buf):\n",
        "        summary(model.model_obj, input_size=(3, 32, 32))\n",
        "        summary_text = buf.getvalue().strip()\n",
        "    if summary_text:\n",
        "        logging.info(\"\\n\" + summary_text)\n",
        "    train_test_instance = train_test_model(model.model_obj,\n",
        "                                          model.device,\n",
        "                                          model.model_config.data_setup_instance.train_loader,\n",
        "                                          model.model_config.data_setup_instance.test_loader,\n",
        "                                          model.model_config.criterion,\n",
        "                                          model.model_config.optimizer,\n",
        "                                          model.model_config.scheduler,\n",
        "                                          model.model_config.epochs)\n",
        "    if (params_check == 0):\n",
        "        train_test_instance.run_epoch()\n",
        "    else:\n",
        "        pass\n",
        "    #train_test_instance.plot_results()\n",
        "    # Capture printed model checks into logs\n",
        "    with io.StringIO() as buf, contextlib.redirect_stdout(buf):\n",
        "        model_checks(model.model_obj)\n",
        "        checks_text = buf.getvalue().strip()\n",
        "    if checks_text:\n",
        "        logging.info(\"\\n\" + checks_text)\n",
        "\n",
        "def main():\n",
        "    # Initialize logging only in the main process\n",
        "    setup_logging(log_to_file=True)\n",
        "    params_check = int(input(\"Enter 1 for params check only, 0 for full training/testing: \"))\n",
        "    main_i(params_check=params_check)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqdgM79MKzZa",
        "outputId": "776d04ac-d9ad-48d3-87b3-a3860bd758dc"
      },
      "id": "vqdgM79MKzZa",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter 1 for params check only, 0 for full training/testing: 0\n",
            "2025-10-03 00:10:14,510 - INFO - Setting up for model\n",
            "2025-10-03 00:10:14,855 - INFO - Model v0 dataloader args: {'batch_size_train': 32, 'batch_size_test': 1000, 'shuffle_train': True, 'shuffle_test': False, 'num_workers': 2, 'pin_memory': True}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "/tmp/ipython-input-2167529188.py:48: UserWarning: Argument(s) 'max_holes, max_height, max_width, min_holes, min_height, min_width, fill_value, mask_fill_value' are not valid for transform CoarseDropout\n",
            "  A.CoarseDropout(\n",
            "100%|| 170M/170M [01:03<00:00, 2.67MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:11:22,027 - INFO - Model v0: OneCycleLR max_lr=0.01 pct_start=0.2 div_factor=10 final_div_factor=100 epochs=35\n",
            "2025-10-03 00:11:22,028 - INFO - Dataloader arguments: {'batch_size_train': 32, 'batch_size_test': 1000, 'shuffle_train': True, 'shuffle_test': False, 'num_workers': 2, 'pin_memory': True}\n",
            "2025-10-03 00:11:23,006 - INFO - \n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 32, 32]             216\n",
            "       BatchNorm2d-2            [-1, 8, 32, 32]              16\n",
            "              ReLU-3            [-1, 8, 32, 32]               0\n",
            "           Dropout-4            [-1, 8, 32, 32]               0\n",
            "            Conv2d-5           [-1, 16, 32, 32]           1,152\n",
            "       BatchNorm2d-6           [-1, 16, 32, 32]              32\n",
            "              ReLU-7           [-1, 16, 32, 32]               0\n",
            "           Dropout-8           [-1, 16, 32, 32]               0\n",
            "            Conv2d-9           [-1, 32, 32, 32]           4,608\n",
            "      BatchNorm2d-10           [-1, 32, 32, 32]              64\n",
            "             ReLU-11           [-1, 32, 32, 32]               0\n",
            "          Dropout-12           [-1, 32, 32, 32]               0\n",
            "           Conv2d-13           [-1, 32, 30, 30]           9,216\n",
            "      BatchNorm2d-14           [-1, 32, 30, 30]              64\n",
            "             ReLU-15           [-1, 32, 30, 30]               0\n",
            "          Dropout-16           [-1, 32, 30, 30]               0\n",
            "           Conv2d-17           [-1, 32, 30, 30]           9,216\n",
            "      BatchNorm2d-18           [-1, 32, 30, 30]              64\n",
            "             ReLU-19           [-1, 32, 30, 30]               0\n",
            "          Dropout-20           [-1, 32, 30, 30]               0\n",
            "           Conv2d-21           [-1, 32, 28, 28]           9,216\n",
            "      BatchNorm2d-22           [-1, 32, 28, 28]              64\n",
            "             ReLU-23           [-1, 32, 28, 28]               0\n",
            "          Dropout-24           [-1, 32, 28, 28]               0\n",
            "           Conv2d-25           [-1, 32, 14, 14]           9,248\n",
            "      BatchNorm2d-26           [-1, 32, 14, 14]              64\n",
            "             ReLU-27           [-1, 32, 14, 14]               0\n",
            "           Conv2d-28           [-1, 32, 14, 14]             288\n",
            "      BatchNorm2d-29           [-1, 32, 14, 14]              64\n",
            "           Conv2d-30           [-1, 64, 14, 14]           2,048\n",
            "      BatchNorm2d-31           [-1, 64, 14, 14]             128\n",
            "DepthwiseSeparableConv-32           [-1, 64, 14, 14]               0\n",
            "           Conv2d-33           [-1, 64, 14, 14]          36,864\n",
            "      BatchNorm2d-34           [-1, 64, 14, 14]             128\n",
            "             ReLU-35           [-1, 64, 14, 14]               0\n",
            "          Dropout-36           [-1, 64, 14, 14]               0\n",
            "           Conv2d-37          [-1, 128, 14, 14]          73,728\n",
            "AdaptiveAvgPool2d-38            [-1, 128, 1, 1]               0\n",
            "          Flatten-39                  [-1, 128]               0\n",
            "           Linear-40                   [-1, 10]           1,290\n",
            "================================================================\n",
            "Total params: 157,778\n",
            "Trainable params: 157,778\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.38\n",
            "Params size (MB): 0.60\n",
            "Estimated Total Size (MB): 5.99\n",
            "----------------------------------------------------------------\n",
            "2025-10-03 00:11:23,006 - INFO - Training model for 35 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0557 Acc=31.64% LR=0.0014: 100%|| 1563/1563 [00:35<00:00, 44.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:11:58,307 - INFO - Epoch 01/35: Train set final results: Average loss: 2787.2644, Accuracy: 15822/50000 (31.64%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=1.5422 Accuracy=40.58%: 100%|| 10/10 [00:01<00:00,  5.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:12:00,098 - INFO - Epoch 01/35:Test set final results: Average loss: 1.5422, Accuracy: 4058/10000 (40.58%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0462 Acc=44.99% LR=0.0027: 100%|| 1563/1563 [00:33<00:00, 46.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:12:33,910 - INFO - Epoch 02/35: Train set final results: Average loss: 2311.1262, Accuracy: 22494/50000 (44.99%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=1.3076 Accuracy=51.86%: 100%|| 10/10 [00:02<00:00,  4.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:12:36,200 - INFO - Epoch 02/35:Test set final results: Average loss: 1.3076, Accuracy: 5186/10000 (51.86%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0401 Acc=53.37% LR=0.0045: 100%|| 1563/1563 [00:35<00:00, 43.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:13:12,172 - INFO - Epoch 03/35: Train set final results: Average loss: 2007.0715, Accuracy: 26685/50000 (53.37%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=1.2655 Accuracy=55.93%: 100%|| 10/10 [00:01<00:00,  5.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:13:13,872 - INFO - Epoch 03/35:Test set final results: Average loss: 1.2655, Accuracy: 5593/10000 (55.93%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0361 Acc=58.73% LR=0.0065: 100%|| 1563/1563 [00:35<00:00, 43.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:13:49,462 - INFO - Epoch 04/35: Train set final results: Average loss: 1802.9942, Accuracy: 29366/50000 (58.73%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=1.1306 Accuracy=59.49%: 100%|| 10/10 [00:01<00:00,  5.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:13:51,171 - INFO - Epoch 04/35:Test set final results: Average loss: 1.1306, Accuracy: 5949/10000 (59.49%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0335 Acc=61.73% LR=0.0083: 100%|| 1563/1563 [00:35<00:00, 43.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:14:27,065 - INFO - Epoch 05/35: Train set final results: Average loss: 1672.6435, Accuracy: 30866/50000 (61.73%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.9751 Accuracy=65.50%: 100%|| 10/10 [00:01<00:00,  6.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:14:28,734 - INFO - Epoch 05/35:Test set final results: Average loss: 0.9751, Accuracy: 6550/10000 (65.50%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0311 Acc=64.55% LR=0.0096: 100%|| 1563/1563 [00:34<00:00, 45.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:15:03,183 - INFO - Epoch 06/35: Train set final results: Average loss: 1556.5277, Accuracy: 32277/50000 (64.55%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.9245 Accuracy=68.02%: 100%|| 10/10 [00:01<00:00,  5.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:15:05,076 - INFO - Epoch 06/35:Test set final results: Average loss: 0.9245, Accuracy: 6802/10000 (68.02%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0293 Acc=66.83% LR=0.0100: 100%|| 1563/1563 [00:33<00:00, 46.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:15:38,828 - INFO - Epoch 07/35: Train set final results: Average loss: 1462.6938, Accuracy: 33415/50000 (66.83%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.7915 Accuracy=72.26%: 100%|| 10/10 [00:01<00:00,  5.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:15:40,555 - INFO - Epoch 07/35:Test set final results: Average loss: 0.7915, Accuracy: 7226/10000 (72.26%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0279 Acc=68.46% LR=0.0100: 100%|| 1563/1563 [00:34<00:00, 45.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:16:14,569 - INFO - Epoch 08/35: Train set final results: Average loss: 1395.5646, Accuracy: 34228/50000 (68.46%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.8167 Accuracy=72.37%: 100%|| 10/10 [00:01<00:00,  6.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:16:16,232 - INFO - Epoch 08/35:Test set final results: Average loss: 0.8167, Accuracy: 7237/10000 (72.37%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0267 Acc=69.92% LR=0.0099: 100%|| 1563/1563 [00:36<00:00, 43.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:16:52,534 - INFO - Epoch 09/35: Train set final results: Average loss: 1333.5776, Accuracy: 34960/50000 (69.92%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.7551 Accuracy=73.94%: 100%|| 10/10 [00:01<00:00,  6.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:16:54,159 - INFO - Epoch 09/35:Test set final results: Average loss: 0.7551, Accuracy: 7394/10000 (73.94%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0256 Acc=71.42% LR=0.0097: 100%|| 1563/1563 [00:34<00:00, 45.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:17:28,465 - INFO - Epoch 10/35: Train set final results: Average loss: 1278.8487, Accuracy: 35709/50000 (71.42%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.7631 Accuracy=73.80%: 100%|| 10/10 [00:01<00:00,  5.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:17:30,154 - INFO - Epoch 10/35:Test set final results: Average loss: 0.7631, Accuracy: 7380/10000 (73.80%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0248 Acc=72.35% LR=0.0095: 100%|| 1563/1563 [00:34<00:00, 45.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:18:04,308 - INFO - Epoch 11/35: Train set final results: Average loss: 1242.1008, Accuracy: 36176/50000 (72.35%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.6824 Accuracy=76.31%: 100%|| 10/10 [00:02<00:00,  4.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:18:06,548 - INFO - Epoch 11/35:Test set final results: Average loss: 0.6824, Accuracy: 7631/10000 (76.31%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0241 Acc=73.26% LR=0.0092: 100%|| 1563/1563 [00:36<00:00, 43.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:18:42,734 - INFO - Epoch 12/35: Train set final results: Average loss: 1203.3715, Accuracy: 36631/50000 (73.26%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.7016 Accuracy=76.34%: 100%|| 10/10 [00:01<00:00,  6.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:18:44,360 - INFO - Epoch 12/35:Test set final results: Average loss: 0.7016, Accuracy: 7634/10000 (76.34%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0234 Acc=73.90% LR=0.0089: 100%|| 1563/1563 [00:33<00:00, 46.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:19:18,217 - INFO - Epoch 13/35: Train set final results: Average loss: 1169.9813, Accuracy: 36949/50000 (73.90%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.6777 Accuracy=77.11%: 100%|| 10/10 [00:01<00:00,  6.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:19:19,822 - INFO - Epoch 13/35:Test set final results: Average loss: 0.6777, Accuracy: 7711/10000 (77.11%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0229 Acc=74.63% LR=0.0085: 100%|| 1563/1563 [00:34<00:00, 45.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:19:54,563 - INFO - Epoch 14/35: Train set final results: Average loss: 1143.6724, Accuracy: 37314/50000 (74.63%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.6173 Accuracy=78.40%: 100%|| 10/10 [00:01<00:00,  6.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:19:56,152 - INFO - Epoch 14/35:Test set final results: Average loss: 0.6173, Accuracy: 7840/10000 (78.40%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0222 Acc=75.20% LR=0.0081: 100%|| 1563/1563 [00:32<00:00, 47.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:20:29,121 - INFO - Epoch 15/35: Train set final results: Average loss: 1110.8866, Accuracy: 37599/50000 (75.20%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.6319 Accuracy=78.73%: 100%|| 10/10 [00:01<00:00,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:20:30,837 - INFO - Epoch 15/35:Test set final results: Average loss: 0.6319, Accuracy: 7873/10000 (78.73%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0216 Acc=76.12% LR=0.0077: 100%|| 1563/1563 [00:33<00:00, 46.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:21:04,653 - INFO - Epoch 16/35: Train set final results: Average loss: 1081.6140, Accuracy: 38059/50000 (76.12%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.5990 Accuracy=79.32%: 100%|| 10/10 [00:01<00:00,  6.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:21:06,258 - INFO - Epoch 16/35:Test set final results: Average loss: 0.5990, Accuracy: 7932/10000 (79.32%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0211 Acc=76.78% LR=0.0072: 100%|| 1563/1563 [00:33<00:00, 46.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:21:40,242 - INFO - Epoch 17/35: Train set final results: Average loss: 1053.9131, Accuracy: 38389/50000 (76.78%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.6066 Accuracy=79.64%: 100%|| 10/10 [00:01<00:00,  6.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:21:41,886 - INFO - Epoch 17/35:Test set final results: Average loss: 0.6066, Accuracy: 7964/10000 (79.64%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0208 Acc=77.02% LR=0.0067: 100%|| 1563/1563 [00:33<00:00, 47.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:22:14,896 - INFO - Epoch 18/35: Train set final results: Average loss: 1039.9282, Accuracy: 38508/50000 (77.02%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.5793 Accuracy=80.81%: 100%|| 10/10 [00:01<00:00,  6.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:22:16,556 - INFO - Epoch 18/35:Test set final results: Average loss: 0.5793, Accuracy: 8081/10000 (80.81%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0205 Acc=77.00% LR=0.0061: 100%|| 1563/1563 [00:36<00:00, 42.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:22:53,332 - INFO - Epoch 19/35: Train set final results: Average loss: 1025.9219, Accuracy: 38501/50000 (77.00%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.5741 Accuracy=80.73%: 100%|| 10/10 [00:01<00:00,  5.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:22:55,028 - INFO - Epoch 19/35:Test set final results: Average loss: 0.5741, Accuracy: 8073/10000 (80.73%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0201 Acc=77.63% LR=0.0056: 100%|| 1563/1563 [00:38<00:00, 40.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:23:33,856 - INFO - Epoch 20/35: Train set final results: Average loss: 1004.9551, Accuracy: 38815/50000 (77.63%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.5470 Accuracy=81.40%: 100%|| 10/10 [00:01<00:00,  5.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:23:35,701 - INFO - Epoch 20/35:Test set final results: Average loss: 0.5470, Accuracy: 8140/10000 (81.40%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0196 Acc=78.30% LR=0.0050: 100%|| 1563/1563 [00:37<00:00, 41.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:24:13,301 - INFO - Epoch 21/35: Train set final results: Average loss: 978.3846, Accuracy: 39149/50000 (78.30%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.5259 Accuracy=82.09%: 100%|| 10/10 [00:01<00:00,  5.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:24:15,029 - INFO - Epoch 21/35:Test set final results: Average loss: 0.5259, Accuracy: 8209/10000 (82.09%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0192 Acc=78.73% LR=0.0044: 100%|| 1563/1563 [00:36<00:00, 42.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:24:51,802 - INFO - Epoch 22/35: Train set final results: Average loss: 962.0642, Accuracy: 39367/50000 (78.73%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.5321 Accuracy=82.21%: 100%|| 10/10 [00:01<00:00,  5.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:24:53,565 - INFO - Epoch 22/35:Test set final results: Average loss: 0.5321, Accuracy: 8221/10000 (82.21%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0189 Acc=79.24% LR=0.0039: 100%|| 1563/1563 [00:37<00:00, 41.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:25:31,478 - INFO - Epoch 23/35: Train set final results: Average loss: 947.2682, Accuracy: 39618/50000 (79.24%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.5049 Accuracy=82.99%: 100%|| 10/10 [00:01<00:00,  5.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:25:33,164 - INFO - Epoch 23/35:Test set final results: Average loss: 0.5049, Accuracy: 8299/10000 (82.99%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0186 Acc=79.39% LR=0.0034: 100%|| 1563/1563 [00:36<00:00, 42.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:26:09,534 - INFO - Epoch 24/35: Train set final results: Average loss: 928.6708, Accuracy: 39697/50000 (79.39%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.5230 Accuracy=82.51%: 100%|| 10/10 [00:02<00:00,  4.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:26:11,718 - INFO - Epoch 24/35:Test set final results: Average loss: 0.5230, Accuracy: 8251/10000 (82.51%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0180 Acc=80.09% LR=0.0028: 100%|| 1563/1563 [00:36<00:00, 42.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:26:48,234 - INFO - Epoch 25/35: Train set final results: Average loss: 901.0948, Accuracy: 40047/50000 (80.09%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.5119 Accuracy=83.04%: 100%|| 10/10 [00:02<00:00,  3.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:26:50,972 - INFO - Epoch 25/35:Test set final results: Average loss: 0.5119, Accuracy: 8304/10000 (83.04%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0177 Acc=80.43% LR=0.0023: 100%|| 1563/1563 [00:35<00:00, 43.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:27:26,719 - INFO - Epoch 26/35: Train set final results: Average loss: 885.2760, Accuracy: 40217/50000 (80.43%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.4777 Accuracy=83.79%: 100%|| 10/10 [00:01<00:00,  5.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:27:28,591 - INFO - Epoch 26/35:Test set final results: Average loss: 0.4777, Accuracy: 8379/10000 (83.79%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0174 Acc=80.79% LR=0.0019: 100%|| 1563/1563 [00:36<00:00, 43.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:28:04,776 - INFO - Epoch 27/35: Train set final results: Average loss: 870.7485, Accuracy: 40396/50000 (80.79%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.4867 Accuracy=83.60%: 100%|| 10/10 [00:01<00:00,  5.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:28:06,458 - INFO - Epoch 27/35:Test set final results: Average loss: 0.4867, Accuracy: 8360/10000 (83.60%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0171 Acc=81.12% LR=0.0015: 100%|| 1563/1563 [00:38<00:00, 40.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:28:44,861 - INFO - Epoch 28/35: Train set final results: Average loss: 856.6689, Accuracy: 40559/50000 (81.12%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.4869 Accuracy=83.29%: 100%|| 10/10 [00:01<00:00,  5.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:28:46,595 - INFO - Epoch 28/35:Test set final results: Average loss: 0.4869, Accuracy: 8329/10000 (83.29%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0166 Acc=81.54% LR=0.0011: 100%|| 1563/1563 [00:37<00:00, 42.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:29:23,739 - INFO - Epoch 29/35: Train set final results: Average loss: 830.7871, Accuracy: 40769/50000 (81.54%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.4607 Accuracy=84.62%: 100%|| 10/10 [00:01<00:00,  5.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:29:25,448 - INFO - Epoch 29/35:Test set final results: Average loss: 0.4607, Accuracy: 8462/10000 (84.62%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0164 Acc=81.98% LR=0.0008: 100%|| 1563/1563 [00:36<00:00, 42.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:30:02,377 - INFO - Epoch 30/35: Train set final results: Average loss: 818.3666, Accuracy: 40992/50000 (81.98%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.4584 Accuracy=84.85%: 100%|| 10/10 [00:01<00:00,  5.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:30:04,059 - INFO - Epoch 30/35:Test set final results: Average loss: 0.4584, Accuracy: 8485/10000 (84.85%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0161 Acc=82.28% LR=0.0005: 100%|| 1563/1563 [00:34<00:00, 45.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:30:38,642 - INFO - Epoch 31/35: Train set final results: Average loss: 805.1573, Accuracy: 41141/50000 (82.28%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.4518 Accuracy=84.85%: 100%|| 10/10 [00:02<00:00,  4.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:30:40,906 - INFO - Epoch 31/35:Test set final results: Average loss: 0.4518, Accuracy: 8485/10000 (84.85%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0159 Acc=82.44% LR=0.0003: 100%|| 1563/1563 [00:33<00:00, 46.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:31:14,748 - INFO - Epoch 32/35: Train set final results: Average loss: 792.7924, Accuracy: 41220/50000 (82.44%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.4559 Accuracy=84.86%: 100%|| 10/10 [00:01<00:00,  6.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:31:16,354 - INFO - Epoch 32/35:Test set final results: Average loss: 0.4559, Accuracy: 8486/10000 (84.86%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0156 Acc=82.78% LR=0.0001: 100%|| 1563/1563 [00:36<00:00, 42.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:31:52,886 - INFO - Epoch 33/35: Train set final results: Average loss: 780.1840, Accuracy: 41389/50000 (82.78%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.4501 Accuracy=84.89%: 100%|| 10/10 [00:01<00:00,  5.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:31:54,644 - INFO - Epoch 33/35:Test set final results: Average loss: 0.4501, Accuracy: 8489/10000 (84.89%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0154 Acc=83.18% LR=0.0000: 100%|| 1563/1563 [00:35<00:00, 44.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:32:30,085 - INFO - Epoch 34/35: Train set final results: Average loss: 768.0875, Accuracy: 41589/50000 (83.18%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.4455 Accuracy=84.90%: 100%|| 10/10 [00:01<00:00,  6.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:32:31,736 - INFO - Epoch 34/35:Test set final results: Average loss: 0.4455, Accuracy: 8490/10000 (84.90%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Loss=0.0153 Acc=83.04% LR=0.0000: 100%|| 1563/1563 [00:35<00:00, 44.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:33:06,831 - INFO - Epoch 35/35: Train set final results: Average loss: 766.9637, Accuracy: 41519/50000 (83.04%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test Loss=0.4484 Accuracy=85.09%: 100%|| 10/10 [00:01<00:00,  6.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-03 00:33:08,482 - INFO - Epoch 35/35:Test set final results: Average loss: 0.4484, Accuracy: 8509/10000 (85.09%)\n",
            "2025-10-03 00:33:08,488 - INFO - \n",
            "2025-10-03 00:33:08,483 - INFO - --- Model Architecture Checks ---\n",
            "2025-10-03 00:33:08,483 - INFO - Total Parameters: 157,778\n",
            "2025-10-03 00:33:08,483 - INFO - Trainable Parameters: 157,778\n",
            "\n",
            "2025-10-03 00:33:08,483 - INFO - Layer-wise Parameter Details (in model order):\n",
            "2025-10-03 00:33:08,484 - INFO - ----------------------------------------------------------------------------------------------------\n",
            "2025-10-03 00:33:08,484 - INFO - \n",
            "Block: c1 (Sequential)\n",
            "2025-10-03 00:33:08,484 - INFO -   c1.0 (Conv2d)                                      | Params:    216 | Convolution: 3->8 channels, kernel (3, 3), stride (1, 1), padding (1, 1), groups 1, bias False\n",
            "2025-10-03 00:33:08,484 - INFO -   c1.1 (BatchNorm2d)                                 | Params:     16 | BatchNorm: 8 features, eps=1e-05, momentum=0.1\n",
            "2025-10-03 00:33:08,484 - INFO -   c1.2 (ReLU)                                        | Params:      0 | Activation: ReLU\n",
            "2025-10-03 00:33:08,484 - INFO -   c1.3 (Dropout)                                     | Params:      0 | Dropout: probability 0.05\n",
            "2025-10-03 00:33:08,484 - INFO -   c1.4 (Conv2d)                                      | Params:  1,152 | Convolution: 8->16 channels, kernel (3, 3), stride (1, 1), padding (1, 1), groups 1, bias False\n",
            "2025-10-03 00:33:08,485 - INFO -   c1.5 (BatchNorm2d)                                 | Params:     32 | BatchNorm: 16 features, eps=1e-05, momentum=0.1\n",
            "2025-10-03 00:33:08,485 - INFO -   c1.6 (ReLU)                                        | Params:      0 | Activation: ReLU\n",
            "2025-10-03 00:33:08,485 - INFO -   c1.7 (Dropout)                                     | Params:      0 | Dropout: probability 0.05\n",
            "2025-10-03 00:33:08,485 - INFO -   c1.8 (Conv2d)                                      | Params:  4,608 | Convolution: 16->32 channels, kernel (3, 3), stride (1, 1), padding (1, 1), groups 1, bias False\n",
            "2025-10-03 00:33:08,485 - INFO -   c1.9 (BatchNorm2d)                                 | Params:     64 | BatchNorm: 32 features, eps=1e-05, momentum=0.1\n",
            "2025-10-03 00:33:08,485 - INFO -   c1.10 (ReLU)                                       | Params:      0 | Activation: ReLU\n",
            "2025-10-03 00:33:08,485 - INFO -   c1.11 (Dropout)                                    | Params:      0 | Dropout: probability 0.05\n",
            "2025-10-03 00:33:08,485 - INFO - \n",
            "Block: c2 (Sequential)\n",
            "2025-10-03 00:33:08,486 - INFO -   c2.0 (Conv2d)                                      | Params:  9,216 | Convolution: 32->32 channels, kernel (3, 3), stride (1, 1), padding (0, 0), groups 1, bias False\n",
            "2025-10-03 00:33:08,486 - INFO -   c2.1 (BatchNorm2d)                                 | Params:     64 | BatchNorm: 32 features, eps=1e-05, momentum=0.1\n",
            "2025-10-03 00:33:08,486 - INFO -   c2.2 (ReLU)                                        | Params:      0 | Activation: ReLU\n",
            "2025-10-03 00:33:08,486 - INFO -   c2.3 (Dropout)                                     | Params:      0 | Dropout: probability 0.05\n",
            "2025-10-03 00:33:08,486 - INFO -   c2.4 (Conv2d)                                      | Params:  9,216 | Convolution: 32->32 channels, kernel (3, 3), stride (1, 1), padding (2, 2), groups 1, bias False\n",
            "2025-10-03 00:33:08,486 - INFO -   c2.5 (BatchNorm2d)                                 | Params:     64 | BatchNorm: 32 features, eps=1e-05, momentum=0.1\n",
            "2025-10-03 00:33:08,486 - INFO -   c2.6 (ReLU)                                        | Params:      0 | Activation: ReLU\n",
            "2025-10-03 00:33:08,486 - INFO -   c2.7 (Dropout)                                     | Params:      0 | Dropout: probability 0.05\n",
            "2025-10-03 00:33:08,486 - INFO -   c2.8 (Conv2d)                                      | Params:  9,216 | Convolution: 32->32 channels, kernel (3, 3), stride (1, 1), padding (0, 0), groups 1, bias False\n",
            "2025-10-03 00:33:08,486 - INFO -   c2.9 (BatchNorm2d)                                 | Params:     64 | BatchNorm: 32 features, eps=1e-05, momentum=0.1\n",
            "2025-10-03 00:33:08,486 - INFO -   c2.10 (ReLU)                                       | Params:      0 | Activation: ReLU\n",
            "2025-10-03 00:33:08,486 - INFO -   c2.11 (Dropout)                                    | Params:      0 | Dropout: probability 0.05\n",
            "2025-10-03 00:33:08,486 - INFO - \n",
            "Block: c3 (Sequential)\n",
            "2025-10-03 00:33:08,486 - INFO -   c3.0 (Conv2d)                                      | Params:  9,248 | Convolution: 32->32 channels, kernel (3, 3), stride (2, 2), padding (1, 1), groups 1, bias True\n",
            "2025-10-03 00:33:08,487 - INFO -   c3.1 (BatchNorm2d)                                 | Params:     64 | BatchNorm: 32 features, eps=1e-05, momentum=0.1\n",
            "2025-10-03 00:33:08,487 - INFO -   c3.2 (ReLU)                                        | Params:      0 | Activation: ReLU\n",
            "2025-10-03 00:33:08,487 - INFO -   c3.3 (DepthwiseSeparableConv)                      | Params:  2,528 | \n",
            "2025-10-03 00:33:08,487 - INFO -   c3.4 (Conv2d)                                      | Params: 36,864 | Convolution: 64->64 channels, kernel (3, 3), stride (1, 1), padding (1, 1), groups 1, bias False\n",
            "2025-10-03 00:33:08,487 - INFO -   c3.5 (BatchNorm2d)                                 | Params:    128 | BatchNorm: 64 features, eps=1e-05, momentum=0.1\n",
            "2025-10-03 00:33:08,487 - INFO -   c3.6 (ReLU)                                        | Params:      0 | Activation: ReLU\n",
            "2025-10-03 00:33:08,487 - INFO -   c3.7 (Dropout)                                     | Params:      0 | Dropout: probability 0.05\n",
            "2025-10-03 00:33:08,487 - INFO - \n",
            "Block: c4 (Sequential)\n",
            "2025-10-03 00:33:08,487 - INFO -   c4.0 (Conv2d)                                      | Params: 73,728 | Convolution: 64->128 channels, kernel (3, 3), stride (1, 1), padding (1, 1), groups 1, bias False\n",
            "2025-10-03 00:33:08,487 - INFO -   c4.1 (AdaptiveAvgPool2d)                           | Params:      0 | AdaptiveAvgPool: output size 1\n",
            "2025-10-03 00:33:08,487 - INFO -   c4.2 (Flatten)                                     | Params:      0 | Flatten\n",
            "2025-10-03 00:33:08,487 - INFO -   c4.3 (Linear)                                      | Params:  1,290 | Linear: 128->10, bias True\n",
            "2025-10-03 00:33:08,487 - INFO - ----------------------------------------------------------------------------------------------------\n",
            "2025-10-03 00:33:08,487 - INFO - \n",
            "Layer Type Summary:\n",
            "2025-10-03 00:33:08,488 - INFO - Conv2d               layers used:  11\n",
            "2025-10-03 00:33:08,488 - INFO - BatchNorm2d          layers used:  10\n",
            "2025-10-03 00:33:08,488 - INFO - ReLU                 layers used:   8\n",
            "2025-10-03 00:33:08,488 - INFO - AdaptiveAvgPool2d    layers used:   1\n",
            "2025-10-03 00:33:08,488 - INFO - Dropout              layers used:   7\n",
            "2025-10-03 00:33:08,488 - INFO - Linear               layers used:   1\n",
            "2025-10-03 00:33:08,488 - INFO - Flatten              layers used:   1\n",
            "2025-10-03 00:33:08,488 - INFO - ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "594058e7",
      "metadata": {
        "id": "594058e7"
      },
      "source": [
        "## Model Architecture Overview\n",
        "\n",
        "The model implements:\n",
        "- **C1**: Initial feature extraction (381632 channels)\n",
        "- **C2**: Dilated convolutions (dilation=1,2,4) maintaining 32x32 spatial size\n",
        "- **C3**: Depthwise Separable Convolution with stride=2 (3264 channels, 16x16)\n",
        "- **C4**: Final convolution with stride=2 (64128 channels, 8x8) + GAP + FC\n",
        "\n",
        "**Key Features:**\n",
        "- Receptive field: 94 pixels (>44 requirement)\n",
        "- Parameters: ~150k (<200k requirement)\n",
        "- Albumentations: HorizontalFlip, ShiftScaleRotate, CoarseDropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e5c0aff",
      "metadata": {
        "id": "4e5c0aff"
      },
      "outputs": [],
      "source": [
        "# Create and analyze the model\n",
        "model = Net()\n",
        "print(f\"Model created successfully!\")\n",
        "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "# Calculate receptive field\n",
        "rf = calculate_receptive_field(model)\n",
        "params = count_parameters(model)\n",
        "\n",
        "print(\"\n",
        "Requirements check:\")\n",
        "print(f\"RF > 44: {'' if rf > 44 else ''} ({rf} > 44)\")\n",
        "print(f\"Parameters < 200k: {'' if params < 200000 else ''} ({params:,} < 200,000)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "976df2e4",
      "metadata": {
        "id": "976df2e4"
      },
      "outputs": [],
      "source": [
        "# Model summary\n",
        "import io\n",
        "import contextlib\n",
        "\n",
        "with io.StringIO() as buf, contextlib.redirect_stdout(buf):\n",
        "    summary(model, input_size=(3, 32, 32))\n",
        "    summary_text = buf.getvalue()\n",
        "\n",
        "print(\"Model Summary:\")\n",
        "print(summary_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c17a538a",
      "metadata": {
        "id": "c17a538a"
      },
      "source": [
        "## Training Setup\n",
        "\n",
        "Now let's set up the training configuration and data loaders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d4b3243",
      "metadata": {
        "id": "2d4b3243"
      },
      "outputs": [],
      "source": [
        "# Setup training\n",
        "model_wrapper = get_model(device=None)\n",
        "print(\"Training setup complete!\")\n",
        "print(f\"Device: {model_wrapper.device}\")\n",
        "print(f\"Epochs: {model_wrapper.model_config.epochs}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d91c370d",
      "metadata": {
        "id": "d91c370d"
      },
      "source": [
        "## Start Training\n",
        "\n",
        "Choose your training mode:\n",
        "- Enter 0 for full training/testing\n",
        "- Enter 1 for parameter check only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fce26ae",
      "metadata": {
        "id": "8fce26ae"
      },
      "outputs": [],
      "source": [
        "# Choose training mode\n",
        "params_check = 0  # Set to 0 for full training, 1 for params check only\n",
        "\n",
        "if params_check == 0:\n",
        "    print(\"Starting FULL TRAINING...\")\n",
        "    main_i(params_check=0)\n",
        "else:\n",
        "    print(\"Parameter check only...\")\n",
        "    main_i(params_check=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJNR6otQ953a"
      },
      "source": [
        "## Results and Analysis\n",
        "\n",
        "After training completes, you can analyze the results:\n",
        "\n",
        "1. **Training curves**: Loss and accuracy over epochs\n",
        "2. **Final accuracy**: Should achieve >85% on CIFAR-10 test set\n",
        "3. **Model performance**: Check if all requirements are met\n",
        "\n",
        "## Key Requirements Met:\n",
        "-  C1C2C3C4 architecture with no MaxPooling\n",
        "-  Last convolution has stride=2\n",
        "-  Receptive field > 44 pixels\n",
        "-  One Depthwise Separable Convolution layer\n",
        "-  One Dilated Convolution layer\n",
        "-  Global Average Pooling (GAP)\n",
        "-  Albumentations data augmentation\n",
        "-  < 200k parameters\n",
        "-  Code modularity\n",
        "-  85% accuracy target\n",
        "\n",
        "## Troubleshooting\n",
        "\n",
        "If you encounter issues:\n",
        "1. Make sure all dependencies are installed\n",
        "2. Check that CUDA is available if using GPU\n",
        "3. Monitor memory usage on Colab\n",
        "4. Training may take 30-60 minutes depending on hardware"
      ],
      "id": "YJNR6otQ953a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1b2df4b",
      "metadata": {
        "id": "c1b2df4b"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install torch torchvision torchsummary numpy matplotlib albumentations tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc7838dd",
      "metadata": {
        "id": "bc7838dd"
      },
      "outputs": [],
      "source": [
        "# Clone the repository (replace with your actual repo URL)\n",
        "!git clone https://github.com/your-username/ERA_v4_cifar_10_model_v1_S7.git\n",
        "%cd ERA_v4_cifar_10_model_v1_S7"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84a95a21",
      "metadata": {
        "id": "84a95a21"
      },
      "source": [
        "## Alternative: Upload Project Files\n",
        "\n",
        "If you prefer to upload the files directly instead of cloning, upload all the .py files from your project to Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3e1b6a0",
      "metadata": {
        "id": "a3e1b6a0"
      },
      "outputs": [],
      "source": [
        "# If uploading files manually, create the project structure\n",
        "# Upload all .py files to Colab and run this cell\n",
        "import os\n",
        "if not os.path.exists('ERA_v4_cifar_10_model_v1_S7'):\n",
        "    os.makedirs('ERA_v4_cifar_10_model_v1_S7')\n",
        "    print(\"Created project directory. Please upload your .py files.\")\n",
        "else:\n",
        "    %cd ERA_v4_cifar_10_model_v1_S7"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fcc915c",
      "metadata": {
        "id": "8fcc915c"
      },
      "source": [
        "## Model Architecture Overview\n",
        "\n",
        "The model implements:\n",
        "- **C1**: Initial feature extraction (381632 channels)\n",
        "- **C2**: Dilated convolutions (dilation=1,2,4) maintaining 32x32 spatial size\n",
        "- **C3**: Depthwise Separable Convolution with stride=2 (3264 channels, 16x16)\n",
        "- **C4**: Final convolution with stride=2 (64128 channels, 8x8) + GAP + FC\n",
        "\n",
        "**Key Features:**\n",
        "- Receptive field: 94 pixels (>44 requirement)\n",
        "- Parameters: ~150k (<200k requirement)\n",
        "- Albumentations: HorizontalFlip, ShiftScaleRotate, CoarseDropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e598c8ab",
      "metadata": {
        "id": "e598c8ab"
      },
      "outputs": [],
      "source": [
        "# Check if all required files are present\n",
        "import os\n",
        "required_files = [\n",
        "    'main.py', 'cifar10model_v0.py', 'data_setup.py', 'data_visual.py',\n",
        "    'train_test.py', 'logger_setup.py', 'summarizer.py'\n",
        "]\n",
        "\n",
        "missing_files = [f for f in required_files if not os.path.exists(f)]\n",
        "if missing_files:\n",
        "    print(f\"Missing files: {missing_files}\")\n",
        "    print(\"Please upload the missing files to continue.\")\n",
        "else:\n",
        "    print(\"All required files are present!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b80380b0",
      "metadata": {
        "id": "b80380b0"
      },
      "outputs": [],
      "source": [
        "# Import and check model\n",
        "try:\n",
        "    from cifar10model_v0 import Net\n",
        "    import torch\n",
        "\n",
        "    # Create model\n",
        "    model = Net()\n",
        "    print(f\"Model created successfully!\")\n",
        "    print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "    # Check receptive field calculation\n",
        "    print(\"\\nRunning receptive field calculation...\")\n",
        "\n",
        "except ImportError as e:\n",
        "    print(f\"Import error: {e}\")\n",
        "    print(\"Please ensure all Python files are uploaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c245d081",
      "metadata": {
        "id": "c245d081"
      },
      "outputs": [],
      "source": [
        "# Run receptive field calculator\n",
        "try:\n",
        "    from receptive_field_calculator import calculate_receptive_field, count_parameters\n",
        "\n",
        "    rf = calculate_receptive_field(model)\n",
        "    params = count_parameters(model)\n",
        "\n",
        "    print(\"\n",
        "Requirements check:\")\n",
        "    print(f\"RF > 44: {'' if rf > 44 else ''} ({rf} > 44)\")\n",
        "    print(f\"Parameters < 200k: {'' if params < 200000 else ''} ({params:,} < 200,000)\")\n",
        "\n",
        "except ImportError:\n",
        "    print(\"Receptive field calculator not found. Creating a simple version...\")\n",
        "\n",
        "    # Simple parameter count\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    print(f\"Total parameters: {total_params:,}\")\n",
        "    print(f\"Parameters < 200k: {'' if total_params < 200000 else ''}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7b222e2",
      "metadata": {
        "id": "e7b222e2"
      },
      "source": [
        "## Data Visualization\n",
        "\n",
        "Let's visualize the CIFAR-10 dataset and understand the data distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1818fbd7",
      "metadata": {
        "id": "1818fbd7"
      },
      "outputs": [],
      "source": [
        "# Visualize CIFAR-10 data\n",
        "try:\n",
        "    from data_visual import data_visual\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    # Create data visualizer\n",
        "    visualizer = data_visual(dataset_name='cifar10')\n",
        "\n",
        "    # Show sample images\n",
        "    visualizer.show_sample_images()\n",
        "\n",
        "    # Show class distribution\n",
        "    visualizer.show_class_distribution()\n",
        "\n",
        "except ImportError as e:\n",
        "    print(f\"Data visualization error: {e}\")\n",
        "    print(\"Continuing without visualization...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e018217d",
      "metadata": {
        "id": "e018217d"
      },
      "source": [
        "## Model Summary\n",
        "\n",
        "Let's examine the model architecture and parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac773a26",
      "metadata": {
        "id": "ac773a26"
      },
      "outputs": [],
      "source": [
        "# Model summary\n",
        "try:\n",
        "    from summarizer import summary\n",
        "    import io\n",
        "    import contextlib\n",
        "\n",
        "    # Capture model summary\n",
        "    with io.StringIO() as buf, contextlib.redirect_stdout(buf):\n",
        "        summary(model, input_size=(3, 32, 32))\n",
        "        summary_text = buf.getvalue()\n",
        "\n",
        "    print(\"Model Summary:\")\n",
        "    print(summary_text)\n",
        "\n",
        "except ImportError as e:\n",
        "    print(f\"Summary error: {e}\")\n",
        "    print(\"Model structure:\")\n",
        "    print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f0b3282",
      "metadata": {
        "id": "2f0b3282"
      },
      "source": [
        "## Training Setup\n",
        "\n",
        "Now let's set up the training configuration and data loaders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8c7f8d2",
      "metadata": {
        "id": "a8c7f8d2"
      },
      "outputs": [],
      "source": [
        "# Setup training\n",
        "try:\n",
        "    from main import get_model\n",
        "\n",
        "    # Create model and configuration\n",
        "    model_wrapper = get_model(model_version=0)\n",
        "    print(\"Training setup complete!\")\n",
        "    print(f\"Device: {model_wrapper.device}\")\n",
        "    print(f\"Epochs: {model_wrapper.model_config.epochs}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Setup error: {e}\")\n",
        "    print(\"Manual setup...\")\n",
        "\n",
        "    # Manual setup if main.py fails\n",
        "    from cifar10model_v0 import Net, set_config_v0\n",
        "    from data_setup import DataSetup\n",
        "\n",
        "    model = Net()\n",
        "    config = set_config_v0()\n",
        "    config.setup(model)\n",
        "    print(\"Manual setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99caef6d",
      "metadata": {
        "id": "99caef6d"
      },
      "source": [
        "## Start Training\n",
        "\n",
        "Finally, let's start the training process. This will train the model for the specified number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4221d64d",
      "metadata": {
        "id": "4221d64d"
      },
      "outputs": [],
      "source": [
        "# Start training\n",
        "try:\n",
        "    from train_test import train_test_model\n",
        "\n",
        "    # Run training\n",
        "    print(\"Starting training...\")\n",
        "    train_test_model(\n",
        "        model_wrapper.model_obj,\n",
        "        model_wrapper.device,\n",
        "        model_wrapper.model_config.data_setup_instance.train_loader,\n",
        "        model_wrapper.model_config.data_setup_instance.test_loader,\n",
        "        model_wrapper.model_config.criterion,\n",
        "        model_wrapper.model_config.optimizer,\n",
        "        model_wrapper.model_config.scheduler\n",
        "    )\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Training error: {e}\")\n",
        "    print(\"Please check the setup and try again.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bb48559",
      "metadata": {
        "id": "9bb48559"
      },
      "source": [
        "## Results and Analysis\n",
        "\n",
        "After training completes, you can analyze the results:\n",
        "\n",
        "1. **Training curves**: Loss and accuracy over epochs\n",
        "2. **Final accuracy**: Should achieve >85% on CIFAR-10 test set\n",
        "3. **Model performance**: Check if all requirements are met\n",
        "\n",
        "## Key Requirements Met:\n",
        "-  C1C2C3C4 architecture with no MaxPooling\n",
        "-  Last convolution has stride=2\n",
        "-  Receptive field > 44 pixels\n",
        "-  One Depthwise Separable Convolution layer\n",
        "-  One Dilated Convolution layer\n",
        "-  Global Average Pooling (GAP)\n",
        "-  Albumentations data augmentation\n",
        "-  < 200k parameters\n",
        "-  Code modularity\n",
        "-  85% accuracy target\n",
        "\n",
        "## Troubleshooting\n",
        "\n",
        "If you encounter issues:\n",
        "1. Make sure all Python files are uploaded\n",
        "2. Check that all dependencies are installed\n",
        "3. Ensure CUDA is available if using GPU\n",
        "4. Monitor memory usage on Colab"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}